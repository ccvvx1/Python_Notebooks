{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KlWbyYyiuLFI"
   },
   "outputs": [],
   "source": [
    "#@title 链接Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uDH1wmnp9AM"
   },
   "outputs": [],
   "source": [
    "#@title 自定义GPT2模型\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from transformers import BertTokenizer, GPT2LMHeadModel,GPT2Config\n",
    "from torch import nn\n",
    "\n",
    "# from utils.utils import get_project_rootpath\n",
    "import os\n",
    "\n",
    "\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GPT2, self).__init__()\n",
    "\n",
    "        # self.gpt = GPT2LMHeadModel.from_pretrained(os.path.join(get_project_rootpath(), \"gpt2-chinese-cluecorpussmall\"))\n",
    "\n",
    "        # self.gpt = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "        config = GPT2Config()\n",
    "        \n",
    "        config.n_embd = 500\n",
    "        config.n_head = 10\n",
    "        config.n_layer = 10\n",
    "        print(config)\n",
    "        self.gpt = GPT2LMHeadModel(config)\n",
    "\n",
    "\n",
    "    def forward(self, batch_inputs):\n",
    "        outputs = self.gpt(input_ids=batch_inputs)\n",
    "        return outputs\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        # 返回模型的配置\n",
    "        return self.gpt.config\n",
    "\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        # Provide the device attribute for the model\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def to(self, device):\n",
    "        # Move the model and its parameters to the specified device\n",
    "        self.gpt.to(device)\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l995WrFwAwef"
   },
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFQfesu0qgZA"
   },
   "outputs": [],
   "source": [
    "#@title 数据加载\n",
    "import json\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "\n",
    "# 将文本数据转换为模型输入的数字编码\n",
    "def make_data(file_path, tokenizer):\n",
    "    # 读取文件内容\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    train_datas = []  # 初始化列表存储处理后的数据\n",
    "    for line in lines:\n",
    "        line = line.strip()  # 去除每行的前后空白字符\n",
    "        # 将文本行中的制表符（\\t）替换为[SEP]，并在行尾加上[SEP]\n",
    "        train_data = [i if i != '\\t' else \"[SEP]\" for i in line] + ['[SEP]']\n",
    "        # 使用tokenizer将文本数据编码为数字序列\n",
    "        # print(\"train_data: \", train_data)\n",
    "        train_num_data = tokenizer.encode(train_data)\n",
    "        train_num_data = train_num_data[:-1]  # 去掉最后一个标记（通常是[SEP]）\n",
    "        train_datas.append(train_num_data)  # 将编码后的数据添加到列表中\n",
    "\n",
    "    return train_datas  # 返回所有处理后的数据\n",
    "\n",
    "\n",
    "# 自定义数据集类，继承自torch.utils.data.Dataset\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, datas, vocab2id):\n",
    "        self.datas = datas  # 保存数据\n",
    "        self.vocab2id = vocab2id  # 保存词汇到ID的映射\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.datas[item]  # 获取指定索引的样本数据\n",
    "        # 划分数据为输入和输出\n",
    "        decoder_input = data[:-1]  # 输入数据，去掉最后一个标记\n",
    "        decoder_output = data[1:]  # 输出数据，从第二个标记开始\n",
    "\n",
    "        # print(\"decoder_input: \", decoder_input, \" decoder_output: \", decoder_output)\n",
    "\n",
    "        # 计算输入和输出的长度\n",
    "        decoder_input_len = len(decoder_input)\n",
    "        decoder_output_len = len(decoder_output)\n",
    "\n",
    "        # 返回样本的输入和输出以及它们的长度\n",
    "        return {\"decoder_input\": decoder_input, \"decoder_input_len\": decoder_input_len,\n",
    "                \"decoder_output\": decoder_output, \"decoder_output_len\": decoder_output_len}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)  # 返回数据集的总长度\n",
    "\n",
    "    def padding_batch(self, batch):\n",
    "        # 获取批次中每个样本的输入和输出长度\n",
    "        decoder_input_lens = [d[\"decoder_input_len\"] for d in batch]\n",
    "        decoder_output_lens = [d[\"decoder_output_len\"] for d in batch]\n",
    "\n",
    "        # 找到输入和输出的最大长度\n",
    "        decoder_input_maxlen = max(decoder_input_lens)\n",
    "        decoder_output_maxlen = max(decoder_output_lens)\n",
    "\n",
    "        # 对每个样本进行填充，使其长度一致\n",
    "        for d in batch:\n",
    "            d[\"decoder_input\"].extend([self.vocab2id[\"[PAD]\"]] * (decoder_input_maxlen - d[\"decoder_input_len\"]))\n",
    "            d[\"decoder_output\"].extend([self.vocab2id[\"[PAD]\"]] * (decoder_output_maxlen - d[\"decoder_output_len\"]))\n",
    "            # print(\"decoder_inputsdecoder_inputs: \", d[\"decoder_input\"], \"decoder_outputdecoder_output:\", d[\"decoder_output\"])\n",
    "\n",
    "        # 将填充后的输入和输出转换为张量\n",
    "        decoder_inputs = torch.tensor([d[\"decoder_input\"] for d in batch], dtype=torch.long)\n",
    "        decoder_outputs = torch.tensor([d[\"decoder_output\"] for d in batch], dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "        return decoder_inputs, decoder_outputs  # 返回填充后的输入和输出张量\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciz7s5bP2GvE",
    "outputId": "aa3e8fdd-333d-4f79-fa25-cae7f999c5f5"
   },
   "outputs": [],
   "source": [
    "#@title 自定义数据\n",
    "\n",
    "%%writefile selfTxt.txt\n",
    "谢谢你所做的一切\n",
    "你开心就好\n",
    "开心\n",
    "\n",
    "你们宿舍都是这么厉害的人吗\n",
    "是的\n",
    "又高又厉害\n",
    "\n",
    "今天好点了吗？\n",
    "一天比一天严重\n",
    "吃药不管用，去打一针。别拖着\n",
    "\n",
    "是的。下辈子想做只萤火虫\n",
    "可是萤火虫太容易被抓了还是改一个吧\n",
    "不，我只想奋不顾身扑火\n",
    "\n",
    "加油，三月动起来，五月笑起来\n",
    "正解你为什么就那么厉害呢\n",
    "哈哈，没办法，智商就是这么高\n",
    "\n",
    "好身材，秀出来\n",
    "哈哈哈其实我是胖的\n",
    "谢谢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxy1gjd1A0am"
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHYB8ERstu-p"
   },
   "outputs": [],
   "source": [
    "#@title AverageMeter\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # 初始化函数，设置各变量初始值为None，并调用reset函数进行重置\n",
    "        self.count = None  # 记录数据的数量\n",
    "        self.sum = None  # 记录数据的总和\n",
    "        self.avg = None  # 记录当前的平均值\n",
    "        self.val = None  # 记录当前值\n",
    "        self.reset()  # 重置所有变量\n",
    "\n",
    "    def reset(self):\n",
    "        # 重置所有变量的值为初始状态\n",
    "        self.val = 0  # 当前值设为0\n",
    "        self.avg = 0  # 平均值设为0\n",
    "        self.sum = 0  # 总和设为0\n",
    "        self.count = 0  # 数据的数量设为0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        # 更新函数，用于更新当前值、总和、数量及重新计算平均值\n",
    "        self.val = val  # 更新当前值为传入的值\n",
    "        self.sum += val * n  # 根据传入的数量n，将总和增加val * n\n",
    "        self.count += n  # 更新数据的数量\n",
    "        self.avg = self.sum / self.count  # 计算新的平均值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z-4JRFdqpGo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][71550/2548664] Loss: 6.3806(4.2066) Elapsed 0min 0s \n",
      "Epoch: [0][71560/2548664] Loss: 3.9618(4.2065) Elapsed 0min 1s \n",
      "Epoch: [0][71570/2548664] Loss: 0.3231(4.2065) Elapsed 0min 1s \n",
      "Epoch: [0][71580/2548664] Loss: 5.3162(4.2066) Elapsed 0min 1s \n",
      "Epoch: [0][71590/2548664] Loss: 4.3241(4.2066) Elapsed 0min 1s \n",
      "Epoch: [0][71600/2548664] Loss: 5.3016(4.2066) Elapsed 0min 1s \n",
      "Epoch: [0][71610/2548664] Loss: 7.7795(4.2067) Elapsed 0min 1s \n",
      "Epoch: [0][71620/2548664] Loss: 3.9665(4.2066) Elapsed 0min 0s \n",
      "Epoch: [0][71630/2548664] Loss: 5.7897(4.2066) Elapsed 0min 0s \n",
      "Epoch: [0][71640/2548664] Loss: 4.9824(4.2065) Elapsed 0min 1s \n",
      "Epoch: [0][71650/2548664] Loss: 4.5995(4.2065) Elapsed 0min 1s \n",
      "Epoch: [0][71660/2548664] Loss: 3.4066(4.2065) Elapsed 0min 1s \n",
      "Epoch: [0][71670/2548664] Loss: 4.3279(4.2066) Elapsed 0min 1s \n",
      "Epoch: [0][71680/2548664] Loss: 4.6340(4.2066) Elapsed 0min 1s \n",
      "Epoch: [0][71690/2548664] Loss: 4.2430(4.2067) Elapsed 0min 0s \n",
      "Epoch: [0][71700/2548664] Loss: 6.6842(4.2066) Elapsed 0min 0s \n",
      "Epoch: [0][71710/2548664] Loss: 4.0904(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71720/2548664] Loss: 4.8087(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71730/2548664] Loss: 6.1094(4.2066) Elapsed 0min 0s \n",
      "Epoch: [0][71740/2548664] Loss: 4.9715(4.2066) Elapsed 0min 0s \n",
      "Epoch: [0][71750/2548664] Loss: 4.4281(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71760/2548664] Loss: 3.8838(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71770/2548664] Loss: 2.2771(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71780/2548664] Loss: 6.3258(4.2066) Elapsed 0min 1s \n",
      "Epoch: [0][71790/2548664] Loss: 6.1499(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71800/2548664] Loss: 4.9110(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71810/2548664] Loss: 6.1480(4.2065) Elapsed 0min 0s \n",
      "Epoch: [0][71820/2548664] Loss: 4.7092(4.2064) Elapsed 0min 0s \n",
      "Epoch: [0][71830/2548664] Loss: 6.5119(4.2064) Elapsed 0min 0s \n",
      "Epoch: [0][71840/2548664] Loss: 3.5533(4.2063) Elapsed 0min 0s \n",
      "Epoch: [0][71850/2548664] Loss: 4.3861(4.2062) Elapsed 0min 1s \n",
      "Epoch: [0][71860/2548664] Loss: 0.3198(4.2060) Elapsed 0min 0s \n",
      "Epoch: [0][71870/2548664] Loss: 4.0673(4.2061) Elapsed 0min 1s \n",
      "Epoch: [0][71880/2548664] Loss: 2.8709(4.2060) Elapsed 0min 1s \n",
      "Epoch: [0][71890/2548664] Loss: 3.1729(4.2060) Elapsed 0min 1s \n",
      "Epoch: [0][71900/2548664] Loss: 4.1527(4.2060) Elapsed 0min 1s \n",
      "Epoch: [0][71910/2548664] Loss: 3.7136(4.2060) Elapsed 0min 1s \n",
      "Epoch: [0][71920/2548664] Loss: 0.4853(4.2059) Elapsed 0min 1s \n",
      "Epoch: [0][71930/2548664] Loss: 2.2804(4.2058) Elapsed 0min 0s \n",
      "Epoch: [0][71940/2548664] Loss: 5.3735(4.2058) Elapsed 0min 0s \n",
      "Epoch: [0][71950/2548664] Loss: 0.4221(4.2057) Elapsed 0min 0s \n",
      "Epoch: [0][71960/2548664] Loss: 5.5218(4.2057) Elapsed 0min 1s \n",
      "Epoch: [0][71970/2548664] Loss: 0.9959(4.2055) Elapsed 0min 0s \n",
      "Epoch: [0][71980/2548664] Loss: 3.6145(4.2054) Elapsed 0min 0s \n",
      "Epoch: [0][71990/2548664] Loss: 8.9888(4.2053) Elapsed 0min 0s \n",
      "Epoch: [0][72000/2548664] Loss: 4.0888(4.2053) Elapsed 0min 0s \n"
     ]
    }
   ],
   "source": [
    "#@title 训练过程\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# 添加上级目录到系统路径中\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# 定义训练参数的类\n",
    "class TrainArgs:\n",
    "    def __init__(self):\n",
    "        self.device = \"cpu\"  # 训练设备（默认为CPU）\n",
    "        self.batch_size = 4  # 批次大小\n",
    "        self.epochs = 1  # 训练轮数\n",
    "        self.print_every = 10  # 每隔多少步打印一次信息\n",
    "        self.clip = 1  # 梯度裁剪的阈值\n",
    "        # 训练数据文件路径\n",
    "        self.train_file_path = \"/content/drive/MyDrive/train.txt\"\n",
    "        self.save_path = \"GPT2.pt\"  # 模型保存路径\n",
    "        self.lr = 1e-4  # 学习率\n",
    "\n",
    "# 实例化 TrainArgs 类\n",
    "train_args = TrainArgs()\n",
    "\n",
    "# 设置训练参数（这些设置在 TrainArgs 类中已经定义）\n",
    "train_args.device = \"cuda\"\n",
    "train_args.batch_size = 1\n",
    "train_args.epochs = 10\n",
    "train_args.print_every = 10\n",
    "train_args.clip = 1\n",
    "# train_args.train_file_path = \"/content/drive/MyDrive/train.txt\"\n",
    "train_args.train_file_path = \"selfTxt.txt\"\n",
    "train_args.train_file_path = \"/home/tmw/shared/train.txt\"\n",
    "\n",
    "train_args.save_path = \"GPT2.pt\"\n",
    "train_args.lr = 1e-4\n",
    "\n",
    "\n",
    "# 计算训练时间的函数\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time  # 计算总时间\n",
    "    elapsed_mins = int(elapsed_time / 60)  # 转换为分钟\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))  # 剩余秒数\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "# 单步训练函数\n",
    "def train_step(model, data_loader, epoch, optimizer, criterion, clip=1, print_every=None):\n",
    "    model.load_state_dict(torch.load('GPT2.pt'))\n",
    "    model.train()  # 设置模型为训练模式\n",
    "\n",
    "    if print_every is None:\n",
    "        print_every = 1  # 如果未指定打印频率，则默认每步打印一次\n",
    "\n",
    "    epoch_loss = 0  # 初始化本轮的总损失\n",
    "    losses = AverageMeter()  # 用于记录损失的类实例\n",
    "    temp_time = time.time()  # 记录当前时间\n",
    "\n",
    "    # 遍历数据加载器中的每个批次\n",
    "    for step, (dec_inputs, dec_outputs) in enumerate(data_loader):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        dec_outputs: [batch_size, tgt_len]\n",
    "        '''\n",
    "        # print(\"dec_inputs: \", dec_inputs, \"dec_outputs: \", dec_outputs)\n",
    "        optimizer.zero_grad()  # 清除之前的梯度\n",
    "        dec_inputs, dec_outputs = dec_inputs.to(device), dec_outputs.to(device)  # 将数据移动到设备上\n",
    "\n",
    "        # 使用模型进行前向传播，输出：[batch_size * tgt_len, tgt_vocab_size]\n",
    "        outputs = model(dec_inputs)\n",
    "        outputs = outputs.logits  # 获取模型的输出\n",
    "        outputs = outputs.view(-1, outputs.size(-1))  # 调整输出的维度\n",
    "        loss = criterion(outputs, dec_outputs.view(-1))  # 计算损失\n",
    "        epoch_loss += loss.item()  # 累加损失\n",
    "        losses.update(loss.item(), batch_size)  # 更新损失记录\n",
    "\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "\n",
    "        # 梯度裁剪，防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()  # 更新模型参数\n",
    "\n",
    "        # 打印训练进度\n",
    "        if print_every and (step + 1) % print_every == 0:\n",
    "            minutes, seconds = epoch_time(temp_time, time.time())\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Elapsed {minutes:s}min {seconds:s}s '\n",
    "                  .format(epoch, step + 1, len(data_loader),\n",
    "                          minutes=minutes.__str__(),\n",
    "                          seconds=seconds.__str__(),\n",
    "                          loss=losses))\n",
    "            temp_time = time.time()  # 重置计时器\n",
    "\n",
    "        if step %1000 == 0:\n",
    "            save_path = train_args.save_path\n",
    "            torch.save(model.state_dict(), save_path)  # 保存模型参数\n",
    "            torch.save(model.gpt.state_dict(), f'simpleGPT2.pt')  # 保存模型参数\n",
    "\n",
    "    return epoch_loss / len(data_loader)  # 返回每轮的平均损失\n",
    "\n",
    "# 训练函数\n",
    "def train(model, dataloader, train_args):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)  # 定义损失函数\n",
    "    lr = train_args.lr  # 学习率\n",
    "    CLIP = train_args.clip  # 梯度裁剪的阈值\n",
    "    print_every = train_args.print_every  # 打印频率\n",
    "    save_path = train_args.save_path  # 模型保存路径\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # 定义优化器\n",
    "\n",
    "    for epoch in range(train_args.epochs):  # 遍历每个训练轮次\n",
    "        start_time = time.time()  # 记录轮次开始时间\n",
    "        train_loss = train_step(model, dataloader, epoch, optimizer, criterion, CLIP, print_every=print_every)  # 进行训练\n",
    "        end_time = time.time()  # 记录轮次结束时间\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)  # 保存模型参数\n",
    "\n",
    "        torch.save(model.gpt.state_dict(), f'simpleGPT2.pt')  # 保存模型参数\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)  # 计算本轮时间\n",
    "        print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f}')  # 打印训练损失\n",
    "\n",
    "# 打印模型参数的总数和可训练参数的数量\n",
    "def print_num_parameters(model):\n",
    "    # 计算总参数数\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'{total_params:,} total parameters.')\n",
    "    # 计算可训练参数数\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'{total_trainable_params:,} training parameters.')\n",
    "\n",
    "# 主函数\n",
    "if __name__ == '__main__':\n",
    "    device = train_args.device  # 获取设备\n",
    "    # 初始化分词器\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "    # torch.save(tokenizer.state_dict(), f'tokenizer.pt')  # 保存模型参数# 保存分词器\n",
    "    tokenizer.save_pretrained('./tokenizer')  # 保存到指定目录\n",
    "\n",
    "    epochs = train_args.epochs  # 训练轮次\n",
    "    batch_size = train_args.batch_size  # 批次大小\n",
    "\n",
    "    train_file_path = train_args.train_file_path  # 训练数据文件路径\n",
    "    datas = make_data(train_file_path, tokenizer)  # 处理数据\n",
    "    dataset = MyDataSet(datas, tokenizer.vocab)  # 创建数据集实例\n",
    "    dataloader = Data.DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.padding_batch)  # 创建数据加载器\n",
    "\n",
    "    model = GPT2().to(device)  # 初始化模型，并将其移动到设备上\n",
    "    train(model, dataloader, train_args)  # 开始训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tnZHu30-tTkA"
   },
   "outputs": [],
   "source": [
    "#@title 训练参数参考\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# from utils.utils import get_project_rootpath\n",
    "import os\n",
    "\n",
    "# checkpoints_dir = os.path.join(get_project_rootpath(), \"model_checkpoints\")\n",
    "\n",
    "\n",
    "def train_parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"训练参数配置\")\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda\", help=\"batch size\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=4, help=\"batch size\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1, help=\"epochs\")\n",
    "    parser.add_argument(\"--print_every\", type=int, default=10, help=\"print every\")\n",
    "    parser.add_argument(\"--clip\", type=int, default=1, help=\"clip\")\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--train_file_path\", type=str, default=os.path.join(\"\",\"/content/drive/MyDrive/train.txt\"),\n",
    "                        help=\"train_file_path\")\n",
    "\n",
    "    parser.add_argument('--save_path', type=str, default=os.path.join(\"\", \"GPT2.pt\"),\n",
    "                        help='decay step')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate')\n",
    "\n",
    "\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11XcDuBv7d10"
   },
   "source": [
    "## 验证\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc8p3ARG7RVU"
   },
   "outputs": [],
   "source": [
    "def get_project_rootpath():\n",
    "    \"\"\"\n",
    "    获取项目根目录。此函数的能力体现在，不论当前module被import到任何位置，都可以正确获取项目根目录\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = os.path.realpath(os.curdir)\n",
    "    while True:\n",
    "        # PyCharm项目中，'.idea'是必然存在的，且名称唯一\n",
    "        if '.idea' in os.listdir(path):\n",
    "            return path\n",
    "        path = os.path.dirname(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPTIR3PC5dy1"
   },
   "outputs": [],
   "source": [
    "#@title validate result\n",
    "\n",
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "model = GPT2().to(device)\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('GPT2.pt'))\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 创建文本生成管道\n",
    "text_generator = TextGenerationPipeline(model.gpt, tokenizer)\n",
    "\n",
    "# 使用模型进行文本生成\n",
    "result = text_generator(\"今天好点了吗？\", max_length=100, do_sample=True)\n",
    "print(result)\n",
    "\n",
    "# 使用模型进行文本生成\n",
    "result = text_generator(\"好身材，秀出来\", max_length=100, do_sample=True)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pV-VzsInnwN8"
   },
   "outputs": [],
   "source": [
    "#@title validate result\n",
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "import torch\n",
    "\n",
    "# 加载tokenizer和模型\n",
    "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\").to('cpu')\n",
    "\n",
    "# 加载训练后的模型权重\n",
    "# model.load_state_dict(torch.load('GPT2.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 创建文本生成管道\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "# 对话互动\n",
    "history = []\n",
    "\n",
    "while True:\n",
    "    # 用户输入\n",
    "    user_input = input(\"你: \")\n",
    "\n",
    "    # 将用户输入加入到对话历史中\n",
    "    history.append(user_input)\n",
    "\n",
    "    # 构造输入给模型\n",
    "    input_text = \" \".join(history)\n",
    "\n",
    "    # 使用模型生成响应\n",
    "    response = text_generator(input_text, max_length=1000, do_sample=True, top_k=50, top_p=0.95)[0]['generated_text']\n",
    "\n",
    "    # 提取模型生成的响应\n",
    "    generated_text = response[len(input_text):].strip()\n",
    "\n",
    "    # 打印模型的响应\n",
    "    print(\"AI:\", generated_text)\n",
    "\n",
    "    # 将模型的响应加入到对话历史中\n",
    "    history.append(generated_text)\n",
    "\n",
    "    # 结束对话条件（可选）\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"再见\", \"拜拜\"]:\n",
    "        print(\"AI: 再见！\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKxI-lKAufs4"
   },
   "source": [
    "## 安卓加载pt模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6s4H02fujHO"
   },
   "outputs": [],
   "source": [
    "#@title 简单加载pt模型文件\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "\n",
    "# 1. 定义或加载 GPT-2 模型架构\n",
    "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "\n",
    "# 2. 加载保存的模型权重（如果有的话）\n",
    "model.load_state_dict(torch.load('simpleGPT2.pt'))\n",
    "\n",
    "# 3. 设置模型为推理模式\n",
    "model.eval()\n",
    "\n",
    "# 4. 进行推理示例\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/content/tokenizer\")\n",
    "input_text = \"你好\"\n",
    "input_ids = tokenizer(input_text, return_tensors='pt')['input_ids']\n",
    "\n",
    "# 推理\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# 获取生成的 token ID 序列\n",
    "generated_ids = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# 结果解码\n",
    "decoded_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# 打印解码后的文本\n",
    "print(decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azXQELIl9l9m"
   },
   "outputs": [],
   "source": [
    "!pip install onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC7PEe5U8PdF"
   },
   "outputs": [],
   "source": [
    "#@title 转成安卓加载\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "# 定义并加载 GPT-2 模型架构\n",
    "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "\n",
    "# 将模型转换为 ONNX 格式\n",
    "model.eval()\n",
    "dummy_input = torch.randint(0, 1000, (1, 10))  # 修改为适当的输入大小\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=14,  # 使用较高的 opset 版本\n",
    "    input_names=['input_ids'],\n",
    "    output_names=['output']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4MS57dyKuaK"
   },
   "outputs": [],
   "source": [
    "!cp model.onnx /content/drive/MyDrive/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
