{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l995WrFwAwef",
        "bxy1gjd1A0am",
        "11XcDuBv7d10"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title 链接Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KlWbyYyiuLFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "cellView": "form",
        "id": "0uDH1wmnp9AM"
      },
      "outputs": [],
      "source": [
        "#@title 自定义GPT2模型\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel\n",
        "from torch import nn\n",
        "\n",
        "# from utils.utils import get_project_rootpath\n",
        "import os\n",
        "\n",
        "\n",
        "class GPT2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GPT2, self).__init__()\n",
        "\n",
        "        # self.gpt = GPT2LMHeadModel.from_pretrained(os.path.join(get_project_rootpath(), \"gpt2-chinese-cluecorpussmall\"))\n",
        "\n",
        "        self.gpt = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
        "\n",
        "\n",
        "    def forward(self, batch_inputs):\n",
        "        outputs = self.gpt(input_ids=batch_inputs)\n",
        "        return outputs\n",
        "\n",
        "    @property\n",
        "    def config(self):\n",
        "        # 返回模型的配置\n",
        "        return self.gpt.config\n",
        "\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        # Provide the device attribute for the model\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def to(self, device):\n",
        "        # Move the model and its parameters to the specified device\n",
        "        self.gpt.to(device)\n",
        "        return self\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据"
      ],
      "metadata": {
        "id": "l995WrFwAwef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 数据加载\n",
        "import json\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_data(file_path, tokenizer):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    train_datas = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        train_data = [i if i != '\\t' else \"[SEP]\" for i in line] + ['[SEP]']\n",
        "        train_num_data = tokenizer.encode(train_data)\n",
        "        train_num_data = train_num_data[:-1]\n",
        "        train_datas.append(train_num_data)\n",
        "\n",
        "    return train_datas\n",
        "\n",
        "\n",
        "class MyDataSet(Data.Dataset):\n",
        "    def __init__(self, datas, vocab2id):\n",
        "        self.datas = datas\n",
        "        self.vocab2id = vocab2id\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        data = self.datas[item]\n",
        "        decoder_input = data[:-1]\n",
        "        decoder_output = data[1:]\n",
        "\n",
        "        decoder_input_len = len(decoder_input)\n",
        "        decoder_output_len = len(decoder_output)\n",
        "\n",
        "        return {\"decoder_input\": decoder_input, \"decoder_input_len\": decoder_input_len,\n",
        "                \"decoder_output\": decoder_output, \"decoder_output_len\": decoder_output_len}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "    def padding_batch(self, batch):\n",
        "        decoder_input_lens = [d[\"decoder_input_len\"] for d in batch]\n",
        "        decoder_output_lens = [d[\"decoder_output_len\"] for d in batch]\n",
        "\n",
        "        decoder_input_maxlen = max(decoder_input_lens)\n",
        "        decoder_output_maxlen = max(decoder_output_lens)\n",
        "\n",
        "        for d in batch:\n",
        "            d[\"decoder_input\"].extend([self.vocab2id[\"[PAD]\"]] * (decoder_input_maxlen - d[\"decoder_input_len\"]))\n",
        "            d[\"decoder_output\"].extend([self.vocab2id[\"[PAD]\"]] * (decoder_output_maxlen - d[\"decoder_output_len\"]))\n",
        "        decoder_inputs = torch.tensor([d[\"decoder_input\"] for d in batch], dtype=torch.long)\n",
        "        decoder_outputs = torch.tensor([d[\"decoder_output\"] for d in batch], dtype=torch.long)\n",
        "\n",
        "        return decoder_inputs, decoder_outputs\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kFQfesu0qgZA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 自定义数据\n",
        "\n",
        "%%writefile selfTxt.txt\n",
        "谢谢你所做的一切\n",
        "你开心就好\n",
        "开心\n",
        "嗯因为你的心里只有学习\n",
        "某某某，还有你\n",
        "这个某某某用的好\n",
        "\n",
        "你们宿舍都是这么厉害的人吗\n",
        "眼睛特别搞笑这土也不好捏但就是觉得挺可爱\n",
        "特别可爱啊\n",
        "\n",
        "今天好点了吗？\n",
        "一天比一天严重\n",
        "吃药不管用，去打一针。别拖着\n",
        "\n",
        "是的。下辈子想做只萤火虫\n",
        "可是萤火虫太容易被抓了还是改一个吧\n",
        "不，我只想奋不顾身扑火\n",
        "\n",
        "加油，三月动起来，五月笑起来\n",
        "正解你为什么就那么厉害呢\n",
        "哈哈，没办法，智商就是这么高\n",
        "你这是要开始得瑟了吗！好啦！你最厉害！\n",
        "哈哈哈哈\n",
        "\n",
        "好身材，秀出来\n",
        "哈哈哈其实我是胖的\n",
        "不会的\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ciz7s5bP2GvE",
        "outputId": "19d0e4d6-1055-4908-ad2c-3258f2c47d6f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing selfTxt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练"
      ],
      "metadata": {
        "id": "bxy1gjd1A0am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title AverageMeter\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.count = None\n",
        "        self.sum = None\n",
        "        self.avg = None\n",
        "        self.val = None\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dHYB8ERstu-p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 训练过程\n",
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "import torch.utils.data as Data\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "class TrainArgs:\n",
        "    def __init__(self):\n",
        "        self.device = \"cpu\"\n",
        "        self.batch_size = 4\n",
        "        self.epochs = 1\n",
        "        self.print_every = 10\n",
        "        self.clip = 1\n",
        "        # self.train_file_path = \"/content/drive/MyDrive/train.txt\"\n",
        "        self.train_file_path = \"/content/selfTxt.txt\"\n",
        "        self.save_path = \"GPT2.pt\"\n",
        "        self.lr = 1e-4\n",
        "\n",
        "# 实例化 TrainArgs\n",
        "train_args = TrainArgs()\n",
        "\n",
        "# 设置属性\n",
        "train_args.device = \"cpu\"\n",
        "train_args.batch_size = 4\n",
        "train_args.epochs = 1\n",
        "train_args.print_every = 10\n",
        "train_args.clip = 1\n",
        "# train_args.train_file_path = \"/content/drive/MyDrive/train.txt\"\n",
        "train_args.train_file_path = \"/content/selfTxt.txt\"\n",
        "train_args.save_path = \"GPT2.pt\"\n",
        "train_args.lr = 1e-4\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "def train_step(model, data_loader, epoch, optimizer, criterion, clip=1, print_every=None):\n",
        "    model.train()\n",
        "\n",
        "    if print_every == 0:\n",
        "        print_every = 1\n",
        "\n",
        "    epoch_loss = 0\n",
        "    losses = AverageMeter()\n",
        "    temp_time = time.time()\n",
        "    for step, (dec_inputs, dec_outputs) in enumerate(data_loader):\n",
        "        '''\n",
        "        dec_inputs: [batch_size, tgt_len]\n",
        "        dec_outputs: [batch_size, tgt_len]\n",
        "        '''\n",
        "        optimizer.zero_grad()\n",
        "        dec_inputs, dec_outputs = dec_inputs.to(device), dec_outputs.to(device)\n",
        "        # outputs: [batch_size * tgt_len, tgt_vocab_size]\n",
        "        outputs = model(dec_inputs)\n",
        "        outputs = outputs.logits\n",
        "        outputs = outputs.view(-1,outputs.size(-1))\n",
        "        loss = criterion(outputs, dec_outputs.view(-1))\n",
        "        epoch_loss += loss.item()\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # 梯度裁剪\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if print_every and (step + 1) % print_every == 0:\n",
        "            minutes, seconds = epoch_time(temp_time, time.time())\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Elapsed {minutes:s}min {seconds:s}s '\n",
        "                  .format(epoch, step + 1, len(data_loader),\n",
        "                          minutes=minutes.__str__(),\n",
        "                          seconds=seconds.__str__(),\n",
        "                          loss=losses))\n",
        "            temp_time = time.time()\n",
        "\n",
        "    return epoch_loss / len(data_loader)\n",
        "\n",
        "\n",
        "def train(model, dataloader, train_args):\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
        "    lr = train_args.lr\n",
        "    CLIP = train_args.clip\n",
        "    print_every = train_args.print_every\n",
        "    save_path = train_args.save_path\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        train_loss = train_step(model, dataloader, epoch, optimizer, criterion, CLIP, print_every=print_every)\n",
        "        end_time = time.time()\n",
        "\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "\n",
        "\n",
        "def print_num_parameters(model):\n",
        "    # Find total parameters and trainable parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f'{total_params:,} total parameters.')\n",
        "    total_trainable_params = sum(\n",
        "\n",
        "        p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'{total_trainable_params:,} training parameters.')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = train_args.device\n",
        "    # tokenizer = BertTokenizer.from_pretrained(os.path.join(get_project_rootpath(), \"gpt2-chinese-cluecorpussmall\"))\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
        "\n",
        "    epochs = train_args.epochs\n",
        "    batch_size = train_args.batch_size\n",
        "\n",
        "    train_file_path = train_args.train_file_path\n",
        "    datas = make_data(train_file_path, tokenizer)\n",
        "    dataset = MyDataSet(datas, tokenizer.vocab)\n",
        "    dataloader = Data.DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.padding_batch)\n",
        "\n",
        "    model = GPT2().to(device)\n",
        "    train(model, dataloader, train_args)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3z-4JRFdqpGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 训练参数参考\n",
        "import argparse\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "# from utils.utils import get_project_rootpath\n",
        "import os\n",
        "\n",
        "# checkpoints_dir = os.path.join(get_project_rootpath(), \"model_checkpoints\")\n",
        "\n",
        "\n",
        "def train_parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"训练参数配置\")\n",
        "    parser.add_argument(\"--device\", type=str, default=\"cuda\", help=\"batch size\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=4, help=\"batch size\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=1, help=\"epochs\")\n",
        "    parser.add_argument(\"--print_every\", type=int, default=10, help=\"print every\")\n",
        "    parser.add_argument(\"--clip\", type=int, default=1, help=\"clip\")\n",
        "\n",
        "\n",
        "    parser.add_argument(\"--train_file_path\", type=str, default=os.path.join(\"\",\"/content/drive/MyDrive/train.txt\"),\n",
        "                        help=\"train_file_path\")\n",
        "\n",
        "    parser.add_argument('--save_path', type=str, default=os.path.join(\"\", \"GPT2.pt\"),\n",
        "                        help='decay step')\n",
        "    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate')\n",
        "\n",
        "\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tnZHu30-tTkA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 验证\n",
        "\n"
      ],
      "metadata": {
        "id": "11XcDuBv7d10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_project_rootpath():\n",
        "    \"\"\"\n",
        "    获取项目根目录。此函数的能力体现在，不论当前module被import到任何位置，都可以正确获取项目根目录\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    path = os.path.realpath(os.curdir)\n",
        "    while True:\n",
        "        # PyCharm项目中，'.idea'是必然存在的，且名称唯一\n",
        "        if '.idea' in os.listdir(path):\n",
        "            return path\n",
        "        path = os.path.dirname(path)\n"
      ],
      "metadata": {
        "id": "Hc8p3ARG7RVU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title validate result\n",
        "\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
        "model = GPT2().to(device)\n",
        "# 加载模型权重\n",
        "model.load_state_dict(torch.load('GPT2.pt'))\n",
        "\n",
        "# 设置模型为评估模式\n",
        "model.eval()\n",
        "\n",
        "# 创建文本生成管道\n",
        "text_generator = TextGenerationPipeline(model.gpt, tokenizer)\n",
        "\n",
        "# 使用模型进行文本生成\n",
        "result = text_generator(\"谢谢你所做的一切\", max_length=100, do_sample=True)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "gPTIR3PC5dy1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}