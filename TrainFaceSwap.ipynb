{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 加密部分"
      ],
      "metadata": {
        "id": "Uh8FBiFHNSax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_qMIdFFbuWoj"
      },
      "outputs": [],
      "source": [
        "#@title 加密encoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_ch, e_ch, opts=None, use_fp16=False):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.e_ch = e_ch\n",
        "        self.opts = opts if opts is not None else {}\n",
        "        self.use_fp16 = use_fp16\n",
        "\n",
        "        if 't' in self.opts:\n",
        "            self.down1 = Downscale(self.in_ch, self.e_ch, kernel_size=5)\n",
        "            self.res1 = ResidualBlock(self.e_ch)\n",
        "            self.down2 = Downscale(self.e_ch, self.e_ch * 2, kernel_size=5)\n",
        "            self.down3 = Downscale(self.e_ch * 2, self.e_ch * 4, kernel_size=5)\n",
        "            self.down4 = Downscale(self.e_ch * 4, self.e_ch * 8, kernel_size=5)\n",
        "            self.down5 = Downscale(self.e_ch * 8, selfa.e_ch * 8, kernel_size=5)\n",
        "            self.res5 = ResidualBlock(self.e_ch * 8)\n",
        "        else:\n",
        "            n_downscales = 4 if 't' not in self.opts else 5\n",
        "            self.down1 = DownscaleBlock(self.in_ch, self.e_ch, n_downscales=n_downscales, kernel_size=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_fp16:\n",
        "            x = x.half()\n",
        "\n",
        "        if 't' in self.opts:\n",
        "            x = self.down1(x)\n",
        "            x = self.res1(x)\n",
        "            x = self.down2(x)\n",
        "            x = self.down3(x)\n",
        "            x = self.down4(x)\n",
        "            x = self.down5(x)\n",
        "            x = self.res5(x)\n",
        "        else:\n",
        "            x = self.down1(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        if 'u' in self.opts:\n",
        "            x = F.normalize(x, p=2, dim=-1)\n",
        "\n",
        "        if self.use_fp16:\n",
        "            x = x.float()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_out_res(self, res):\n",
        "        return res // (2**4 if 't' not in self.opts else 2**5)\n",
        "\n",
        "    def get_out_ch(self):\n",
        "        return self.e_ch * 8\n",
        "\n",
        "# 下面是 Downscale 和 ResidualBlock 的示例实现（需要根据你的情况具体实现）\n",
        "class Downscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=5):\n",
        "        super(Downscale, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=2, padding=kernel_size//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "class DownscaleBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, n_downscales, kernel_size=5):\n",
        "        super(DownscaleBlock, self).__init__()\n",
        "        layers = []\n",
        "        for _ in range(n_downscales):\n",
        "            layers.append(Downscale(in_ch, out_ch, kernel_size))\n",
        "            in_ch = out_ch\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "# Example instantiation\n",
        "model = Encoder(in_ch=3, e_ch=64, opts={'t': False}, use_fp16=False)\n",
        "# Save model weights\n",
        "torch.save(model.state_dict(), 'encoder_weights.pth')\n"
      ],
      "metadata": {
        "id": "YYWpX1BZBl0y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 解密部分"
      ],
      "metadata": {
        "id": "cvkA7WT3NYqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 解密decoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Upscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
        "        super(Upscale, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=kernel_size // 2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upsample(x)\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_ch, d_ch, d_mask_ch):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.upscale0 = Upscale(in_ch, d_ch * 8, kernel_size=3)\n",
        "        self.upscale1 = Upscale(d_ch * 8, d_ch * 4, kernel_size=3)\n",
        "        self.upscale2 = Upscale(d_ch * 4, d_ch * 2, kernel_size=3)\n",
        "        self.res0 = ResidualBlock(d_ch * 8, kernel_size=3)\n",
        "        self.res1 = ResidualBlock(d_ch * 4, kernel_size=3)\n",
        "        self.res2 = ResidualBlock(d_ch * 2, kernel_size=3)\n",
        "\n",
        "        self.upscalem0 = Upscale(in_ch, d_mask_ch * 8, kernel_size=3)\n",
        "        self.upscalem1 = Upscale(d_mask_ch * 8, d_mask_ch * 4, kernel_size=3)\n",
        "        self.upscalem2 = Upscale(d_mask_ch * 4, d_mask_ch * 2, kernel_size=3)\n",
        "\n",
        "        self.out_conv = nn.Conv2d(d_ch * 2, 3, kernel_size=1)\n",
        "        self.out_conv1 = nn.Conv2d(d_ch * 2, 3, kernel_size=3, padding=1)\n",
        "        self.out_conv2 = nn.Conv2d(d_ch * 2, 3, kernel_size=3, padding=1)\n",
        "        self.out_conv3 = nn.Conv2d(d_ch * 2, 3, kernel_size=3, padding=1)\n",
        "        self.upscalem3 = Upscale(d_mask_ch * 2, d_mask_ch * 1, kernel_size=3)\n",
        "        self.out_convm = nn.Conv2d(d_mask_ch * 1, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Decoder path\n",
        "        x = self.upscale0(z)\n",
        "        x = self.res0(x)\n",
        "        x = self.upscale1(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.upscale2(x)\n",
        "        x = self.res2(x)\n",
        "\n",
        "        # Combine the output of multiple conv layers and apply pixel shuffle\n",
        "        x = torch.cat([\n",
        "            self.out_conv(x),\n",
        "            self.out_conv1(x),\n",
        "            self.out_conv2(x),\n",
        "            self.out_conv3(x)\n",
        "        ], dim=1)\n",
        "\n",
        "        x = F.pixel_shuffle(x, upscale_factor=2)  # Equivalent to depth_to_space\n",
        "\n",
        "        # Mask path\n",
        "        m = self.upscalem0(z)\n",
        "        m = self.upscalem1(m)\n",
        "        m = self.upscalem2(m)\n",
        "        m = self.upscalem3(m)\n",
        "        m = torch.sigmoid(self.out_convm(m))\n",
        "\n",
        "        return x, m\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch, kernel_size=3):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(ch, ch, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "        self.conv2 = nn.Conv2d(ch, ch, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x + residual)\n"
      ],
      "metadata": {
        "id": "XQ55BNBLKZoM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model\n",
        "in_ch = 3\n",
        "d_ch = 64\n",
        "d_mask_ch = 32\n",
        "decoder = Decoder(in_ch, d_ch, d_mask_ch)\n",
        "\n",
        "# Create a dummy input tensor (e.g., batch of images with 3 channels and 64x64 size)\n",
        "dummy_input = torch.randn(1, in_ch, 64, 64)  # Batch size of 1, 3 channels, 64x64\n",
        "\n",
        "# Forward pass\n",
        "x, m = decoder(dummy_input)\n",
        "\n",
        "print(x.shape)  # Output shape of the main decoder path\n",
        "print(m.shape)  # Output shape of the mask path\n"
      ],
      "metadata": {
        "id": "slfHdqx2NytA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(decoder.state_dict(), 'decoder_weights.pth')\n"
      ],
      "metadata": {
        "id": "UYafdLzPQ-2t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 处理inner"
      ],
      "metadata": {
        "id": "A6oQsOybWa_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title inner模型\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Upscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
        "        super(Upscale, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=kernel_size // 2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upsample(x)\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class Inter(nn.Module):\n",
        "    def __init__(self, in_ch, ae_ch, ae_out_ch, lowest_dense_res, opts=None, use_fp16=False):\n",
        "        super(Inter, self).__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.ae_ch = ae_ch\n",
        "        self.ae_out_ch = ae_out_ch\n",
        "        self.lowest_dense_res = lowest_dense_res\n",
        "        self.opts = opts if opts is not None else {}\n",
        "        self.use_fp16 = use_fp16\n",
        "\n",
        "        self.dense1 = nn.Linear(in_ch, ae_ch)\n",
        "        self.dense2 = nn.Linear(ae_ch, lowest_dense_res * lowest_dense_res * ae_out_ch)\n",
        "\n",
        "        if 't' not in self.opts:\n",
        "            self.upscale1 = Upscale(ae_out_ch, ae_out_ch)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = inp\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "\n",
        "        # Reshape the tensor to 4D (batch_size, channels, height, width)\n",
        "        x = x.view(-1, self.ae_out_ch, self.lowest_dense_res, self.lowest_dense_res)\n",
        "\n",
        "        if self.use_fp16:\n",
        "            x = x.half()\n",
        "\n",
        "        if 't' not in self.opts:\n",
        "            x = self.upscale1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_out_res(self):\n",
        "        return self.lowest_dense_res * 2 if 't' not in self.opts else self.lowest_dense_res\n",
        "\n",
        "    def get_out_ch(self):\n",
        "        return self.ae_out_ch\n"
      ],
      "metadata": {
        "id": "4s3jWc1vWesb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 调试inner\n",
        "\n",
        "# Parameters\n",
        "in_ch = 256\n",
        "ae_ch = 128\n",
        "ae_out_ch = 64\n",
        "lowest_dense_res = 16\n",
        "opts = {}  # or {'t': True} to modify behavior\n",
        "use_fp16 = False\n",
        "\n",
        "# Create model\n",
        "inter = Inter(in_ch, ae_ch, ae_out_ch, lowest_dense_res, opts, use_fp16)\n",
        "\n",
        "# Dummy input\n",
        "dummy_input = torch.randn(1, in_ch)  # Batch size of 1, flattened input\n",
        "\n",
        "# Forward pass\n",
        "output = inter(dummy_input)\n",
        "\n",
        "print(output.shape)  # Output shape\n"
      ],
      "metadata": {
        "id": "lcfRxKJdWomV",
        "outputId": "3a2d6300-f448-449c-d9e0-f479962e1f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(inter.state_dict(), 'inter_weights.pth')\n"
      ],
      "metadata": {
        "id": "YcFY16QsW3Sp"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}