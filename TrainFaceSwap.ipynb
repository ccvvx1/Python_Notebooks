{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_qMIdFFbuWoj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_ch, e_ch, opts=None, use_fp16=False):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.e_ch = e_ch\n",
        "        self.opts = opts if opts is not None else {}\n",
        "        self.use_fp16 = use_fp16\n",
        "\n",
        "        if 't' in self.opts:\n",
        "            self.down1 = Downscale(self.in_ch, self.e_ch, kernel_size=5)\n",
        "            self.res1 = ResidualBlock(self.e_ch)\n",
        "            self.down2 = Downscale(self.e_ch, self.e_ch * 2, kernel_size=5)\n",
        "            self.down3 = Downscale(self.e_ch * 2, self.e_ch * 4, kernel_size=5)\n",
        "            self.down4 = Downscale(self.e_ch * 4, self.e_ch * 8, kernel_size=5)\n",
        "            self.down5 = Downscale(self.e_ch * 8, self.e_ch * 8, kernel_size=5)\n",
        "            self.res5 = ResidualBlock(self.e_ch * 8)\n",
        "        else:\n",
        "            n_downscales = 4 if 't' not in self.opts else 5\n",
        "            self.down1 = DownscaleBlock(self.in_ch, self.e_ch, n_downscales=n_downscales, kernel_size=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_fp16:\n",
        "            x = x.half()\n",
        "\n",
        "        if 't' in self.opts:\n",
        "            x = self.down1(x)\n",
        "            x = self.res1(x)\n",
        "            x = self.down2(x)\n",
        "            x = self.down3(x)\n",
        "            x = self.down4(x)\n",
        "            x = self.down5(x)\n",
        "            x = self.res5(x)\n",
        "        else:\n",
        "            x = self.down1(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        if 'u' in self.opts:\n",
        "            x = F.normalize(x, p=2, dim=-1)\n",
        "\n",
        "        if self.use_fp16:\n",
        "            x = x.float()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_out_res(self, res):\n",
        "        return res // (2**4 if 't' not in self.opts else 2**5)\n",
        "\n",
        "    def get_out_ch(self):\n",
        "        return self.e_ch * 8\n",
        "\n",
        "# 下面是 Downscale 和 ResidualBlock 的示例实现（需要根据你的情况具体实现）\n",
        "class Downscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=5):\n",
        "        super(Downscale, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=2, padding=kernel_size//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "class DownscaleBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, n_downscales, kernel_size=5):\n",
        "        super(DownscaleBlock, self).__init__()\n",
        "        layers = []\n",
        "        for _ in range(n_downscales):\n",
        "            layers.append(Downscale(in_ch, out_ch, kernel_size))\n",
        "            in_ch = out_ch\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n"
      ]
    }
  ]
}