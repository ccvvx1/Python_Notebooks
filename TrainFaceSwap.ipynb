{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title 链接Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4mg38E-Oae38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/workspace.zip"
      ],
      "metadata": {
        "id": "YJKreKKabBR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 加密部分"
      ],
      "metadata": {
        "id": "Uh8FBiFHNSax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_qMIdFFbuWoj"
      },
      "outputs": [],
      "source": [
        "#@title 加密encoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_ch, e_ch, opts=None, use_fp16=False):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.e_ch = e_ch\n",
        "        self.opts = opts if opts is not None else {}\n",
        "        self.use_fp16 = use_fp16\n",
        "\n",
        "        if 't' in self.opts:\n",
        "            self.down1 = Downscale(self.in_ch, self.e_ch, kernel_size=5)\n",
        "            self.res1 = ResidualBlock(self.e_ch)\n",
        "            self.down2 = Downscale(self.e_ch, self.e_ch * 2, kernel_size=5)\n",
        "            self.down3 = Downscale(self.e_ch * 2, self.e_ch * 4, kernel_size=5)\n",
        "            self.down4 = Downscale(self.e_ch * 4, self.e_ch * 8, kernel_size=5)\n",
        "            self.down5 = Downscale(self.e_ch * 8, self.e_ch * 8, kernel_size=5)\n",
        "            self.res5 = ResidualBlock(self.e_ch * 8)\n",
        "        else:\n",
        "            n_downscales = 4 if 't' not in self.opts else 5\n",
        "            self.down1 = DownscaleBlock(self.in_ch, self.e_ch, n_downscales=n_downscales, kernel_size=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_fp16:\n",
        "            x = x.half()\n",
        "\n",
        "        if 't' in self.opts:\n",
        "            x = self.down1(x)\n",
        "            x = self.res1(x)\n",
        "            x = self.down2(x)\n",
        "            x = self.down3(x)\n",
        "            x = self.down4(x)\n",
        "            x = self.down5(x)\n",
        "            x = self.res5(x)\n",
        "        else:\n",
        "            x = self.down1(x)\n",
        "\n",
        "        # print(\"encoder str shape:\", x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        if 'u' in self.opts:\n",
        "            x = F.normalize(x, p=2, dim=-1)\n",
        "\n",
        "        if self.use_fp16:\n",
        "            x = x.float()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_out_res(self, res):\n",
        "        return res // (2**4 if 't' not in self.opts else 2**5)\n",
        "\n",
        "    def get_out_ch(self):\n",
        "        return self.e_ch * 8\n",
        "\n",
        "# 下面是 Downscale 和 ResidualBlock 的示例实现（需要根据你的情况具体实现）\n",
        "class Downscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=5):\n",
        "        super(Downscale, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=2, padding=kernel_size//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "class DownscaleBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, n_downscales, kernel_size=5):\n",
        "        super(DownscaleBlock, self).__init__()\n",
        "        layers = []\n",
        "        for _ in range(n_downscales):\n",
        "            layers.append(Downscale(in_ch, out_ch, kernel_size))\n",
        "            in_ch = out_ch\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "# Example instantiation\n",
        "model = Encoder(in_ch=3, e_ch=512, opts={'t': False}, use_fp16=False)\n",
        "print(model)\n",
        "# Save model weights\n",
        "# torch.save(model.state_dict(), 'encoder_weights.pth')\n"
      ],
      "metadata": {
        "id": "YYWpX1BZBl0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 解密部分"
      ],
      "metadata": {
        "id": "cvkA7WT3NYqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 解密decoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Upscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
        "        super(Upscale, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=kernel_size // 2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upsample(x)\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class DecoderSrc(nn.Module):\n",
        "    def __init__(self, in_ch, d_ch, d_mask_ch):\n",
        "        super(DecoderSrc, self).__init__()\n",
        "        self.upscale0 = Upscale(in_ch, d_ch * 8, kernel_size=3)\n",
        "        self.upscale1 = Upscale(d_ch * 8, d_ch * 4, kernel_size=3)\n",
        "        self.upscale2 = Upscale(d_ch * 4, d_ch * 2, kernel_size=3)\n",
        "        self.res0 = ResidualBlock(d_ch * 8, kernel_size=3)\n",
        "        self.res1 = ResidualBlock(d_ch * 4, kernel_size=3)\n",
        "        self.res2 = ResidualBlock(d_ch * 2, kernel_size=3)\n",
        "\n",
        "        self.upscalem0 = Upscale(in_ch, d_mask_ch * 8, kernel_size=3)\n",
        "        self.upscalem1 = Upscale(d_mask_ch * 8, d_mask_ch * 4, kernel_size=3)\n",
        "        self.upscalem2 = Upscale(d_mask_ch * 4, d_mask_ch * 2, kernel_size=3)\n",
        "\n",
        "        self.out_conv = nn.Conv2d(d_ch * 2, 3, kernel_size=1)\n",
        "        self.out_conv1 = nn.Conv2d(d_ch * 2, 3, kernel_size=3, padding=1)\n",
        "        self.out_conv2 = nn.Conv2d(d_ch * 2, 3, kernel_size=3, padding=1)\n",
        "        self.out_conv3 = nn.Conv2d(d_ch * 2, 3, kernel_size=3, padding=1)\n",
        "        self.upscalem3 = Upscale(d_mask_ch * 2, d_mask_ch * 1, kernel_size=3)\n",
        "        self.out_convm = nn.Conv2d(d_mask_ch * 1, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Decoder path\n",
        "        x = self.upscale0(z)\n",
        "        x = self.res0(x)\n",
        "        x = self.upscale1(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.upscale2(x)\n",
        "        x = self.res2(x)\n",
        "\n",
        "        # Combine the output of multiple conv layers and apply pixel shuffle\n",
        "        x = torch.cat([\n",
        "            self.out_conv(x),\n",
        "            self.out_conv1(x),\n",
        "            self.out_conv2(x),\n",
        "            self.out_conv3(x)\n",
        "        ], dim=1)\n",
        "\n",
        "        x = F.pixel_shuffle(x, upscale_factor=2)  # Equivalent to depth_to_space\n",
        "\n",
        "        # Mask path\n",
        "        m = self.upscalem0(z)\n",
        "        m = self.upscalem1(m)\n",
        "        m = self.upscalem2(m)\n",
        "        m = self.upscalem3(m)\n",
        "        m = torch.sigmoid(self.out_convm(m))\n",
        "\n",
        "        return x, m\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch, kernel_size=3):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(ch, ch, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "        self.conv2 = nn.Conv2d(ch, ch, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x + residual)\n"
      ],
      "metadata": {
        "id": "XQ55BNBLKZoM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model\n",
        "in_ch = 128\n",
        "d_ch = 64\n",
        "d_mask_ch = 16\n",
        "decoder = DecoderSrc(in_ch, d_ch, d_mask_ch)\n",
        "\n",
        "print(decoder)\n",
        "\n"
      ],
      "metadata": {
        "id": "slfHdqx2NytA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 保存权重\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(decoder.state_dict(), 'decoder_weights.pth')\n"
      ],
      "metadata": {
        "id": "UYafdLzPQ-2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 读取png文件"
      ],
      "metadata": {
        "id": "5zZEqTimbuIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "        if not self.image_files:\n",
        "            raise ValueError(f\"No PNG files found in directory {image_dir}\")\n",
        "        print(f\"Found {len(self.image_files)} PNG files.\")  # Debug line\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        imageGrey = Image.open(img_name).convert('L')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            imageGrey = self.transform(imageGrey)\n",
        "        return image, imageGrey\n",
        "\n",
        "# Define your transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96, 96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x / 255.0)  # Normalize to [0, 1]\n",
        "])\n",
        "\n",
        "# Specify the path to your image directory\n",
        "image_dir = '/content/data_dst/aligned'\n",
        "\n",
        "# Create dataset and DataLoader\n",
        "dataset = CustomImageDataset(image_dir=image_dir, transform=transform)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Example usage\n",
        "for images, imageGrey in data_loader:\n",
        "    print(images.shape, imageGrey.shape)  # Output the shape of the image batch\n"
      ],
      "metadata": {
        "id": "yti--lFhbxbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 计算loss"
      ],
      "metadata": {
        "id": "6n7RAI9FexaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 计算loss\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "def ssim(x, y, max_val=1.0, filter_size=11):\n",
        "    # Placeholder for SSIM calculation\n",
        "    # You need to replace this with the actual implementation of SSIM\n",
        "    return torch.ones_like(x)  # Dummy implementation\n",
        "\n",
        "# Assume gpu_target_src_masked_opt, gpu_pred_src_src_masked_opt, gpu_target_srcm, gpu_pred_src_srcm are tensors\n",
        "# and resolution is defined\n",
        "\n",
        "# Example tensors and resolution (Replace with actual tensors and value)\n",
        "gpu_target_src_masked_opt = torch.rand((batch_size, channels, height, width))\n",
        "gpu_pred_src_src_masked_opt = torch.rand((batch_size, channels, height, width))\n",
        "gpu_target_srcm = torch.rand((batch_size, channels, height, width))\n",
        "gpu_pred_src_srcm = torch.rand((batch_size, channels, height, width))\n",
        "resolution = 224  # Example resolution\n",
        "\n",
        "# SSIM calculation\n",
        "filter_size = int(resolution / 11.6)\n",
        "dssim = ssim(gpu_target_src_masked_opt, gpu_pred_src_src_masked_opt, max_val=1.0, filter_size=filter_size)\n",
        "\n",
        "# Compute loss\n",
        "gpu_src_loss = torch.mean(10 * dssim, dim=1)\n",
        "gpu_src_loss += torch.mean(10 * torch.square(gpu_target_src_masked_opt - gpu_pred_src_src_masked_opt), dim=[1, 2, 3])\n",
        "gpu_src_loss += torch.mean(10 * torch.square(gpu_target_srcm - gpu_pred_src_srcm), dim=[1, 2, 3])\n"
      ],
      "metadata": {
        "id": "B54LghjzewbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 通过keras的summary改成pytorch"
      ],
      "metadata": {
        "id": "O9vWuNJGfPHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 更好的inter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 假设的常量定义（你需要根据实际情况修改这些值）\n",
        "lowest_dense_res = 6  # 例如，设置为 32 或其他合适的值\n",
        "\n",
        "# 定义你的模型类（之前已经给出）\n",
        "class Inter(nn.Module):\n",
        "    def __init__(self, in_ch, ae_ch, ae_out_ch, opts=None, use_fp16=False):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.ae_ch = ae_ch\n",
        "        self.ae_out_ch = ae_out_ch\n",
        "        self.opts = opts if opts is not None else []\n",
        "        self.use_fp16 = use_fp16\n",
        "\n",
        "        self.dense1 = nn.Linear(in_ch, ae_ch)\n",
        "        self.dense2 = nn.Linear(ae_ch, lowest_dense_res * lowest_dense_res * ae_out_ch)\n",
        "\n",
        "        if 't' not in self.opts:\n",
        "            self.upscale1 = Upscale(ae_out_ch, ae_out_ch)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = inp\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = x.view(-1, self.ae_out_ch, lowest_dense_res, lowest_dense_res)\n",
        "\n",
        "        if self.use_fp16:\n",
        "            x = x.half()\n",
        "\n",
        "        if 't' not in self.opts:\n",
        "            x = self.upscale1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_out_res(self):\n",
        "        return lowest_dense_res * 2 if 't' not in self.opts else lowest_dense_res\n",
        "\n",
        "    def get_out_ch(self):\n",
        "        return self.ae_out_ch\n",
        "\n",
        "class Upscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
        "        super(Upscale, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch * 4, kernel_size=kernel_size, padding='same')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.leaky_relu(x, negative_slope=0.1)\n",
        "        # print(\"x 1 shape: \", x.shape)\n",
        "        x = self.pixel_shuffle(x, upscale_factor=2)\n",
        "        # print(\"x 2 shape: \", x.shape)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def pixel_shuffle(x, upscale_factor):\n",
        "        batch_size, in_channels, height, width = x.size()\n",
        "        out_channels = in_channels // (upscale_factor ** 2)\n",
        "        new_height = height * upscale_factor\n",
        "        new_width = width * upscale_factor\n",
        "\n",
        "        x = x.view(batch_size, out_channels, upscale_factor, upscale_factor, height, width)\n",
        "        x = x.permute(0, 1, 4, 2, 5, 3)\n",
        "        x = x.contiguous().view(batch_size, out_channels, new_height, new_width)\n",
        "        return x\n",
        "\n",
        "# 创建模型实例\n",
        "in_channels = 18432   # 输入通道数\n",
        "ae_channels = 32  # 自编码器的通道数\n",
        "ae_out_channels = 128  # 自编码器输出的通道数\n",
        "opts = []  # 可选参数\n",
        "use_fp16 = False  # 是否使用 FP16\n",
        "\n",
        "dummy_input = torch.randn(32, in_channels)\n",
        "\n",
        "model = Inter(in_channels, ae_channels, ae_out_channels, opts, use_fp16)\n",
        "output = model(dummy_input)\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "id": "eJaXTGu1z5me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 算法\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Upscale(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
        "        super(Upscale, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch * 4, kernel_size=kernel_size, padding='same')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.leaky_relu(x, negative_slope=0.1)\n",
        "        x = self.pixel_shuffle(x, upscale_factor=2)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def pixel_shuffle(x, upscale_factor):\n",
        "        batch_size, in_channels, height, width = x.size()\n",
        "        out_channels = in_channels // (upscale_factor ** 2)\n",
        "        new_height = height * upscale_factor\n",
        "        new_width = width * upscale_factor\n",
        "\n",
        "        x = x.view(batch_size, out_channels, upscale_factor, upscale_factor, height, width)\n",
        "        x = x.permute(0, 1, 4, 2, 5, 3)\n",
        "        x = x.contiguous().view(batch_size, out_channels, new_height, new_width)\n",
        "        return x\n",
        "\n",
        "\n",
        "# 创建一个输入张量 (batch_size, channels, height, width)\n",
        "input_tensor = torch.randn(1, 3, 128, 128)  # 例如，一个 batch size 为 1，通道数为 3，高度和宽度为 32 的张量\n",
        "\n",
        "\n",
        "# 创建模型实例\n",
        "model = Upscale(in_ch=3, out_ch=3, kernel_size=3)  # 例如，输入通道为 3，输出通道为 6\n",
        "\n",
        "\n",
        "# 将输入张量传递给模型\n",
        "output_tensor = model(input_tensor)\n",
        "\n",
        "# 打印输出张量的形状\n",
        "print(output_tensor.shape)  # 输出的形状应该是 (1, 6, 64, 64) 因为 `upscale_factor` 为 2"
      ],
      "metadata": {
        "id": "lfCEv9jpJPmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics scikit-image"
      ],
      "metadata": {
        "id": "hD4lkbRMs8Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 训练\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchmetrics.functional as tmf\n",
        "from itertools import chain\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchmetrics as tm\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "encoder = Encoder(3, 512)  # Adjust parameters as needed\n",
        "\n",
        "# Example optimizer\n",
        "\n",
        "num_epochs = 3000\n",
        "# 检查是否可以使用GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Parameters\n",
        "in_ch = 256\n",
        "ae_ch = 128\n",
        "ae_out_ch = 64\n",
        "lowest_dense_res = 3\n",
        "opts = {}  # or {'t': True} to modify behavior\n",
        "use_fp16 = False\n",
        "\n",
        "\n",
        "# 创建模型实例\n",
        "in_channels = 18432   # 输入通道数\n",
        "# in_channels = 18432   # 输入通道数\n",
        "ae_channels = 32  # 自编码器的通道数\n",
        "ae_out_channels = 128  # 自编码器输出的通道数\n",
        "opts = []  # 可选参数\n",
        "use_fp16 = False  # 是否使用 FP16\n",
        "\n",
        "inter = Inter(in_channels, ae_channels, ae_out_channels, opts, use_fp16)\n",
        "# Create model\n",
        "# inter = Inter()\n",
        "\n",
        "# Initialize the model\n",
        "in_ch = 128\n",
        "d_ch = 64\n",
        "d_mask_ch = 16\n",
        "decoder = DecoderSrc(in_ch, d_ch, d_mask_ch)\n",
        "\n",
        "# 检查是否可以使用GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 将模型移动到设备 (GPU 或 CPU)\n",
        "encoder = encoder.to(device)\n",
        "inter = inter.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    chain(encoder.parameters(), inter.parameters(), decoder.parameters()),\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 文件路径\n",
        "file_path = \"/content/drive/MyDrive/model_epoch.pth\"\n",
        "\n",
        "# 判断文件是否存在\n",
        "if os.path.exists(file_path):\n",
        "\n",
        "    try:\n",
        "      checkpoint = torch.load(f\"/content/drive/MyDrive/model_epoch.pth\")  # 加载特定 epoch 的检查点\n",
        "\n",
        "      # 恢复模型的状态字典\n",
        "      encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "      inter.load_state_dict(checkpoint['inter_state_dict'])\n",
        "      decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
        "\n",
        "      # 恢复优化器的状态\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "      # 恢复其他训练信息（例如 epoch 和 loss）\n",
        "      epoch = checkpoint['epoch']\n",
        "      loss = checkpoint['loss']\n",
        "\n",
        "      print(f\"Model loaded from epoch {epoch} with loss {loss.item()}\")\n",
        "      print(f\"{file_path} exists.\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "else:\n",
        "    print(f\"{file_path} does not exist.\")\n",
        "\n",
        "# 用于存储灰度图像的列表\n",
        "gray_images_list = []\n",
        "x_gray_images_list = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    bPrint = True\n",
        "    bPrintSimple = True\n",
        "    for batch in data_loader:\n",
        "        images, imageGrey = batch  # Move images to the appropriate device (e.g., GPU)\n",
        "        images = images.to(device)\n",
        "        imageGrey = imageGrey.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        encoder_output = encoder(images)\n",
        "        # print(\"encoder shape:\", encoder_output.shape)\n",
        "\n",
        "        # Forward pass\n",
        "        inter_output = inter(encoder_output)\n",
        "        # print(\"inter_output shape: \", inter_output.shape)\n",
        "        x, m = decoder(inter_output)\n",
        "\n",
        "        resolution = 96\n",
        "        # Assuming you have `resolution`, `gpu_target_src_masked_opt`, and `gpu_pred_src_src_masked_opt` defined\n",
        "        filter_size = int(resolution / 11.6)\n",
        "\n",
        "        ssim_value = tmf.structural_similarity_index_measure(imageGrey, m, data_range=1, kernel_size=3)\n",
        "\n",
        "\n",
        "        # DSSIM 是 1 - SSIM\n",
        "        dssim_value = 1 - ssim_value\n",
        "\n",
        "        # 可以将 DSSIM 乘以权重，例如 10，作为 loss\n",
        "        gpu_src_loss = torch.mean(dssim_value * 10)\n",
        "\n",
        "\n",
        "        # Example loss computation (Replace with your actual loss function)\n",
        "        # loss = some_loss_function(encoder_output, target)\n",
        "\n",
        "        # # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        gpu_src_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if bPrintSimple:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {gpu_src_loss.item()}\")\n",
        "            bPrintSimple = False\n",
        "\n",
        "        # 每 100 个 epoch 保存一次模型\n",
        "        if (epoch + 1) % 3 == 0 and bPrint:\n",
        "            bPrint = False\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'encoder_state_dict': encoder.state_dict(),\n",
        "                'inter_state_dict': inter.state_dict(),\n",
        "                'decoder_state_dict': decoder.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': gpu_src_loss\n",
        "            }, f\"/content/drive/MyDrive/model_epoch.pth\")\n",
        "            print(f\"Model saved at epoch {epoch+1}\")\n",
        "\n",
        "            # 假设 x 和 x1 是形状为 [batch_size, channels, height, width] 的张量\n",
        "            # 将 x 和 x1 转换为 NumPy 数组\n",
        "            x = images.cpu().detach().numpy()\n",
        "            x1 = images.cpu().detach().numpy()  # 确保 x1 变量是正确的\n",
        "\n",
        "            # 创建保存目录（如果不存在）\n",
        "            output_dir = \"saved_images\"\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            # 遍历保存每一张图片\n",
        "            for i in range(min(5, x.shape[0])):  # 保存最多 5 张图片\n",
        "                # 转换 x 和 x1 为 [height, width, channels] 形状\n",
        "                img_array_x = np.transpose(x[i], (1, 2, 0))\n",
        "                img_array_x = np.clip(img_array_x * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "                img_array_x1 = np.transpose(x1[i], (1, 2, 0))\n",
        "                img_array_x1 = np.clip(img_array_x1 * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "                # 将 NumPy 数组转换为 PIL Image 对象\n",
        "                img_x = Image.fromarray(img_array_x)\n",
        "                img_x1 = Image.fromarray(img_array_x1)\n",
        "\n",
        "                # 合并两张图片（左右拼接）\n",
        "                width_x = img_x.width\n",
        "                height_x = img_x.height\n",
        "\n",
        "                width_x1 = img_x1.width\n",
        "                height_x1 = img_x1.height\n",
        "\n",
        "                # 确保两张图片的高度相同，否则需要调整大小\n",
        "                if height_x != height_x1:\n",
        "                    img_x1 = img_x1.resize((width_x1, height_x))  # 调整大小\n",
        "                    img_array_x1 = np.array(img_x1)\n",
        "                    img_array_x1 = np.clip(img_array_x1, 0, 255).astype(np.uint8)\n",
        "                    img_x1 = Image.fromarray(img_array_x1)\n",
        "\n",
        "                img_x_combined = Image.new('RGB', (width_x + width_x1, height_x))\n",
        "                img_x_combined.paste(img_x, (0, 0))\n",
        "                img_x_combined.paste(img_x1, (width_x, 0))\n",
        "\n",
        "                # 保存合并后的图片\n",
        "                img_x_combined.save(os.path.join(output_dir, f\"combined_image_{i+1}.png\"))\n",
        "\n",
        "                print(f\"Saved combined_image_{i+1}.png\")"
      ],
      "metadata": {
        "id": "9g4Q9s_YkzhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}