{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "HF4V7xbVCl_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "stock_symbol = 'AAPL'\n",
        "start_date = '2023-01-01'\n",
        "end_date = '2023-12-31'\n",
        "stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
        "print(stock_data.head())\n",
        "\n",
        "# 保存为 CSV 文件\n",
        "file_name = '/kaggle/input/amazon.csv'\n",
        "stock_data.to_csv(file_name)\n",
        "\n",
        "print(f\"数据已保存为 {file_name}\")"
      ],
      "metadata": {
        "id": "K6J2_j0DCpNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /kaggle/input"
      ],
      "metadata": {
        "id": "fcOABX6qly_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /kaggle/input"
      ],
      "metadata": {
        "id": "wU7s0kLkz2dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /kaggle/input/amazon.csv\n",
        "Date,更新,Main,Even,Loss,凯利指数_主,凯利指数_平,凯利指数_客,Result,赔付率_主,赔付率_客,指数\n",
        "2024/09/17 18:00(终),赛前0小时0分,2.38,41.81,28.03,30.16,1.01,0.97,1.00,1.00,3,1.00,1.00\n",
        "2024/09/17 17:55,赛前0小时4分,2.38,41.81,28.03,30.16,1.02,0.96,1.00,1.00,1.00,1.00,3\n",
        "2024/09/17 17:51,赛前0小时8分,2.32,42.81,27.98,29.21,0.99,0.96,1.02,0.99,3\n",
        "2024/09/17 17:48,赛前0小时11分,2.32,42.98,27.70,29.32,1.00,0.97,1.02,1.00,3\n",
        "2024/09/17 17:45,赛前0小时14分,2.28,43.75,27.33,28.92,0.98,0.98,1.04,1.00,3\n",
        "2024/09/17 17:32,赛前0小时27分,2.26,43.97,27.22,28.81,0.97,0.98,1.04,0.99,3\n",
        "2024/09/17 17:23,赛前0小时36分,2.26,44.11,26.58,29.31,0.97,1.01,1.03,1.00,3\n",
        "2024/09/17 17:20,赛前0小时39分,2.28,43.69,26.57,29.74,0.98,1.00,1.01,1.00,3\n",
        "2024/09/17 17:04,赛前0小时55分,2.26,43.91,26.46,29.63,0.97,1.01,1.02,0.99,3\n",
        "2024/09/17 16:55,赛前1小时4分,2.26,44.11,26.58,29.31,0.96,1.01,1.03,1.00,3\n",
        "2024/09/17 16:51,赛前1小时8分,2.28,43.38,27.10,29.52,0.97,0.98,1.02,0.99,3\n",
        "2024/09/17 16:45,赛前1小时14分,2.30,43.17,27.20,29.63,0.98,0.99,1.02,0.99,3\n",
        "2024/09/17 16:42,赛前1小时17分,2.34,42.39,27.55,30.06,1.00,0.97,1.00,0.99,3\n",
        "2024/09/17 16:36,赛前1小时23分,2.22,44.73,26.48,28.79,0.94,1.01,1.05,0.99,3\n",
        "2024/09/17 16:30,赛前1小时29分,2.28,43.38,27.10,29.52,0.97,0.99,1.02,0.99,3\n",
        "2024/09/17 16:21,赛前1小时38分,2.28,43.57,27.22,29.21,0.97,0.99,1.04,0.99,3\n",
        "2024/09/17 16:08,赛前1小时51分,2.26,43.78,27.11,29.11,0.96,0.99,1.03,0.99,3\n",
        "2024/09/17 15:55,赛前2小时4分,2.30,43.19,27.59,29.22,0.98,0.97,1.04,0.99,3\n",
        "2024/09/17 15:49,赛前2小时10分,2.30,43.00,27.48,29.52,0.98,0.97,1.02,0.99,3\n",
        "2024/09/17 15:31,赛前2小时28分,2.30,43.17,27.20,29.63,0.97,0.99,1.03,0.99,3\n",
        "2024/09/17 15:21,赛前2小时38分,2.32,42.76,27.18,30.06,0.98,0.99,1.02,0.99,3\n",
        "2024/09/17 15:03,赛前2小时56分,2.32,42.60,27.45,29.95,0.97,0.98,1.02,0.99,3\n",
        "2024/09/17 14:57,赛前3小时2分,2.28,42.83,27.13,30.04,0.95,0.98,1.01,0.98,3\n",
        "2024/09/17 14:54,赛前3小时5分,2.28,43.03,27.25,29.72,0.95,0.98,1.03,0.98,3\n",
        "2024/09/17 14:51,赛前3小时8分,2.34,42.00,27.30,30.70,0.97,0.98,1.00,0.98,3\n",
        "2024/09/17 14:48,赛前3小时11分,2.34,42.19,27.43,30.38,0.97,0.98,1.02,0.99,3\n",
        "2024/09/17 14:42,赛前3小时17分,2.34,42.00,27.30,30.70,0.97,0.98,1.00,0.98,3\n",
        "2024/09/17 14:39,赛前3小时20分,2.34,41.79,27.16,31.05,0.97,0.98,0.99,0.98,3\n",
        "2024/09/17 14:36,赛前3小时23分,2.34,41.63,27.44,30.93,0.97,0.97,0.99,0.97,3\n",
        "2024/09/17 14:33,赛前3小时26分,2.36,41.26,27.82,30.92,0.98,0.95,0.98,0.97,3\n",
        "2024/09/17 14:30,赛前3小时29分,2.38,40.85,27.78,31.37,0.99,0.95,0.97,0.97,3\n",
        "2024/09/17 14:27,赛前3小时32分,2.40,40.65,27.88,31.47,1.00,0.95,0.96,0.98,3\n",
        "2024/09/17 14:24,赛前3小时35分,2.40,40.69,28.31,31.00,1.00,0.94,0.98,0.98,3\n",
        "2024/09/17 14:21,赛前3小时38分,2.36,41.46,27.96,30.58,0.99,0.95,0.99,0.98,3\n",
        "2024/09/17 14:18,赛前3小时41分,2.34,41.87,27.99,30.14,0.99,0.95,0.99,0.98,3\n",
        "2024/09/17 14:14,赛前3小时45分,2.32,42.27,28.02,29.71,0.99,0.95,1.00,0.98,3\n",
        "2024/09/17 14:11,赛前3小时48分,2.32,42.28,28.43,29.29,0.99,0.94,1.02,0.98,3\n",
        "2024/09/17 14:08,赛前3小时51分,2.28,42.71,28.23,29.06,0.97,0.94,1.02,0.97,3\n",
        "2024/09/17 13:59,赛前4小时0分,2.26,42.92,28.12,28.96,0.96,0.94,1.02,0.97,3"
      ],
      "metadata": {
        "id": "vp5O_iE5yzjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# 原始文件路径\n",
        "source_file = '/kaggle/input/amazon.csv'\n",
        "\n",
        "# 目标目录\n",
        "destination_dir = '/kaggle/input/'\n",
        "\n",
        "# 复制文件\n",
        "for i in range(200):\n",
        "    new_file_name = f'amazon_copy_{i + 1}.csv'\n",
        "    destination_file = os.path.join(destination_dir, new_file_name)\n",
        "    shutil.copy(source_file, destination_file)\n",
        "\n",
        "print(\"文件复制完成！\")\n"
      ],
      "metadata": {
        "id": "af8XuyGkn4ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "CbHXI5I4hp_o"
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rtylZCOghp_r"
      },
      "cell_type": "code",
      "source": [
        "# filepath = '/kaggle/input/stock-time-series-20050101-to-20171231/AMZN_2006-01-01_to_2018-01-01.csv'\n",
        "filepath = '/kaggle/input/amazon.csv'\n",
        "data = pd.read_csv(filepath)\n",
        "data = data.sort_values('Date')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=data)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "XF4qSyRFmQx_"
      }
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8ehyV_uihp_s"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize = (15,9))\n",
        "plt.plot(data[['Main']])\n",
        "plt.plot(data[['Even']])\n",
        "plt.plot(data[['Loss']])\n",
        "plt.xticks(range(0,data.shape[0],500),data['Date'].loc[::500],rotation=45)\n",
        "plt.title(\"Amazon Stock Price\",fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Date',fontsize=18)\n",
        "plt.ylabel('Close Price (USD)',fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrjH2cFEhp_s"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalize data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PRbJWPxZhp_t"
      },
      "cell_type": "code",
      "source": [
        "dataMain = data[['Main']]\n",
        "dataEven = data[['Even']]\n",
        "dataLoss = data[['Loss']]\n",
        "dataResult = data[['Result']]\n",
        "# price.info()\n",
        "# dataLoss\n",
        "# dataLoss['Loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jZZj-Etjhp_u"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scalerMain = MinMaxScaler(feature_range=(-1, 1))\n",
        "scalerEven = MinMaxScaler(feature_range=(-1, 1))\n",
        "scalerLoss = MinMaxScaler(feature_range=(-1, 1))\n",
        "scalerResult = MinMaxScaler(feature_range=(-1, 1))\n",
        "dataMain['Main'] = scalerMain.fit_transform(dataMain['Main'].values.reshape(-1,1))\n",
        "dataEven['Even'] = scalerEven.fit_transform(dataEven['Even'].values.reshape(-1,1))\n",
        "dataLoss['Loss'] = scalerLoss.fit_transform(dataLoss['Loss'].values.reshape(-1,1))\n",
        "dataResult['Result'] = scalerResult.fit_transform(dataResult['Result'].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fx4S1tcNhp_x"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_data(dataMain, dataEven, dataLoss, dataResult, lookback):\n",
        "    data_raw_main = dataMain.to_numpy()\n",
        "    data_raw_even = dataEven.to_numpy()\n",
        "    data_raw_loss = dataLoss.to_numpy()\n",
        "    data_raw_result = dataResult.to_numpy()\n",
        "    data_main = []\n",
        "    data_even = []\n",
        "    data_loss = []\n",
        "    data_result = []\n",
        "\n",
        "    # create all possible sequences of length lookback\n",
        "    for index in range(len(data_raw_main) - lookback):\n",
        "        data_main.append(data_raw_main[index: index + lookback])\n",
        "    for index in range(len(data_raw_even) - lookback):\n",
        "        data_even.append(data_raw_even[index: index + lookback])\n",
        "    for index in range(len(data_raw_loss) - lookback):\n",
        "        data_loss.append(data_raw_loss[index: index + lookback])\n",
        "    for index in range(len(data_raw_result) - lookback):\n",
        "        data_result.append(data_raw_result[index: index + lookback])\n",
        "\n",
        "    data_main = np.array(data_main)\n",
        "    data_even = np.array(data_even)\n",
        "    data_loss = np.array(data_loss)\n",
        "    data_result = np.array(data_result)\n",
        "\n",
        "    test_set_size = int(np.round(0.2 * data_main.shape[0]))\n",
        "    train_set_size = data_main.shape[0] - test_set_size\n",
        "\n",
        "    x_train = {\n",
        "        'main': data_main[:train_set_size, :-1, :],\n",
        "        'even': data_even[:train_set_size, :-1, :],\n",
        "        'loss': data_loss[:train_set_size, :-1, :],\n",
        "        'result': data_result[:train_set_size, :-1, :]\n",
        "    }\n",
        "    y_train = {\n",
        "        'main': data_main[:train_set_size, -1, :],\n",
        "        'even': data_even[:train_set_size, -1, :],\n",
        "        'loss': data_loss[:train_set_size, -1, :],\n",
        "        'result': data_result[:train_set_size, -1, :]\n",
        "    }\n",
        "\n",
        "    x_test = {\n",
        "        'main': data_main[train_set_size:, :-1, :],\n",
        "        'even': data_even[train_set_size:, :-1, :],\n",
        "        'loss': data_loss[train_set_size:, :-1, :],\n",
        "        'result': data_result[train_set_size:, :-1, :]\n",
        "    }\n",
        "    y_test = {\n",
        "        'main': data_main[train_set_size:, -1, :],\n",
        "        'even': data_even[train_set_size:, -1, :],\n",
        "        'loss': data_loss[train_set_size:, -1, :],\n",
        "        'result': data_result[train_set_size:, -1, :]\n",
        "    }\n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]\n",
        "\n",
        "\n",
        "lookback = 10 # choose sequence length\n",
        "x_train, y_train, x_test, y_test = split_data(dataMain, dataEven, dataLoss, dataResult, lookback)\n",
        "# x_train_batches, y_train_batches, x_test, y_test = split_data(price, lookback=20, batch_size=32)\n",
        "\n",
        "# # 打印批次的数量和每个批次的形状\n",
        "# print('Number of training batches:', len(x_train_batches))\n",
        "# if len(x_train_batches) > 0:\n",
        "#     print('Shape of each training batch (x):', x_train_batches[0].shape)\n",
        "#     print('Shape of each training batch (y):', y_train_batches[0].shape)\n",
        "\n",
        "# print('x_test.shape = ', x_test.shape)\n",
        "# print('y_test.shape = ', y_test.shape)\n",
        "\n",
        "print('x_train.shape = ',x_train['main'].shape)\n",
        "print('y_train.shape = ',y_train['main'].shape)\n",
        "print('x_test.shape = ',x_test['main'].shape)\n",
        "print('y_test.shape = ',y_test['main'].shape)\n",
        "\n",
        "# print(\"x_train: \", x_train)\n",
        "# print(\"y_train: \", y_train)\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# 转换为字典\n",
        "train_tensors = {\n",
        "    'x_main': torch.from_numpy(x_train['main']).type(torch.Tensor),\n",
        "    'x_even': torch.from_numpy(x_train['even']).type(torch.Tensor),\n",
        "    'x_loss': torch.from_numpy(x_train['loss']).type(torch.Tensor),\n",
        "    'x_result': torch.from_numpy(x_train['result']).type(torch.Tensor),\n",
        "    'y_main': torch.from_numpy(y_train['main']).type(torch.Tensor),\n",
        "    'y_even': torch.from_numpy(y_train['even']).type(torch.Tensor),\n",
        "    'y_loss': torch.from_numpy(y_train['loss']).type(torch.Tensor),\n",
        "    'y_result': torch.from_numpy(y_train['result']).type(torch.Tensor)\n",
        "}\n",
        "\n",
        "test_tensors = {\n",
        "    'x_main': torch.from_numpy(x_test['main']).type(torch.Tensor),\n",
        "    'x_even': torch.from_numpy(x_test['even']).type(torch.Tensor),\n",
        "    'x_loss': torch.from_numpy(x_test['loss']).type(torch.Tensor),\n",
        "    'x_result': torch.from_numpy(x_test['result']).type(torch.Tensor),\n",
        "    'y_main': torch.from_numpy(y_test['main']).type(torch.Tensor),\n",
        "    'y_even': torch.from_numpy(y_test['even']).type(torch.Tensor),\n",
        "    'y_loss': torch.from_numpy(y_test['loss']).type(torch.Tensor),\n",
        "    'y_result': torch.from_numpy(y_test['result']).type(torch.Tensor)\n",
        "}\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_dim = 1\n",
        "hidden_dim = 32\n",
        "num_layers = 2\n",
        "output_dim = 1\n",
        "output_cls_dim = 3\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.fcCls = nn.Linear(hidden_dim, output_cls_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        out1 = self.fc(out[:, -1, :])\n",
        "\n",
        "        # 通过全连接层\n",
        "        outCls = self.fcCls(out[:, -1, :])\n",
        "        # 应用 softmax 激活\n",
        "        outCls = torch.softmax(outCls, dim=1)\n",
        "\n",
        "        return out1, outCls\n",
        "\n",
        "\n",
        "\n",
        "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterionCls = nn.CrossEntropyLoss()\n",
        "# optimizerCls = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "from re import X\n",
        "import time\n",
        "\n",
        "hist = np.zeros(num_epochs)\n",
        "start_time = time.time()\n",
        "lstm = []\n",
        "\n",
        "y_train_pred_main = None\n",
        "y_train_pred_even = None\n",
        "y_train_pred_loss = None\n",
        "\n",
        "# 假设输入数据\n",
        "# x = torch.randn(23, 3)  # batch_size 为 32，序列长度为 10，输入维度为 10\n",
        "\n",
        "# 创建标签数组\n",
        "labels = torch.zeros(23, dtype=torch.long)  # 初始化为 0\n",
        "\n",
        "# 全部填充为 2\n",
        "labels.fill_(2)\n",
        "\n",
        "for t in range(num_epochs):\n",
        "\n",
        "    y_train_pred_main, cls_main = model(train_tensors['x_main'])\n",
        "    y_train_pred_even, cls_even = model(train_tensors['x_even'])\n",
        "    y_train_pred_loss, cls_loss = model(train_tensors['x_loss'])\n",
        "\n",
        "    loss_main = criterion(y_train_pred_main, train_tensors['y_main'])\n",
        "    loss_even = criterion(y_train_pred_even, train_tensors['y_even'])\n",
        "    loss_loss = criterion(y_train_pred_loss, train_tensors['y_loss'])\n",
        "\n",
        "    # validity = discriminator(img_main)\n",
        "    tmp = torch.softmax(cls_main + cls_even + cls_loss, dim=1)\n",
        "    loss_result = criterionCls(tmp, labels)\n",
        "    loss = loss_main + loss_even + loss_loss + loss_result\n",
        "    print(\"Epoch \", t, \"MSE: \", loss.item(), \"cls_main + cls_even + cls_loss: \", tmp)\n",
        "    # print(\"Epoch \", t, \"MSE: \", loss.item())\n",
        "    hist[t] = loss.item()\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "training_time = time.time()-start_time\n",
        "print(\"Training time: {}\".format(training_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bHIAMIClhp_y"
      },
      "cell_type": "code",
      "source": [
        "predict_main = pd.DataFrame(scalerMain.inverse_transform(y_train_pred_main.detach().numpy()))\n",
        "original_main = pd.DataFrame(scalerMain.inverse_transform(train_tensors['y_main'].detach().numpy()))\n",
        "\n",
        "predict_even = pd.DataFrame(scalerEven.inverse_transform(y_train_pred_even.detach().numpy()))\n",
        "original_even = pd.DataFrame(scalerEven.inverse_transform(train_tensors['y_even'].detach().numpy()))\n",
        "\n",
        "predict_loss = pd.DataFrame(scalerLoss.inverse_transform(y_train_pred_loss.detach().numpy()))\n",
        "original_loss = pd.DataFrame(scalerLoss.inverse_transform(train_tensors['y_loss'].detach().numpy()))\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "ax = sns.lineplot(x = original_main.index, y = original_main[0], label=\"Data Main\", color='royalblue')\n",
        "ax = sns.lineplot(x = predict_main.index, y = predict_main[0], label=\"Training Prediction Main(LSTM)\", color='tomato')\n",
        "\n",
        "ax = sns.lineplot(x = original_even.index, y = original_even[0], label=\"Data Even\", color='red')\n",
        "ax = sns.lineplot(x = predict_even.index, y = predict_even[0], label=\"Training Prediction Even(LSTM)\", color='#FF6347')\n",
        "\n",
        "ax = sns.lineplot(x = original_loss.index, y = original_loss[0], label=\"Data Loss\", color='green')\n",
        "ax = sns.lineplot(x = predict_loss.index, y = predict_loss[0], label=\"Training Prediction Loss(LSTM)\", color='#F31347')\n",
        "ax.set_title('Stock price', size = 14, fontweight='bold')\n",
        "ax.set_xlabel(\"Days\", size = 14)\n",
        "ax.set_ylabel(\"Cost (USD)\", size = 14)\n",
        "ax.set_xticklabels('', size=10)\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "ax = sns.lineplot(data=hist, color='royalblue')\n",
        "ax.set_xlabel(\"Epoch\", size = 14)\n",
        "ax.set_ylabel(\"Loss\", size = 14)\n",
        "ax.set_title(\"Training Loss\", size = 14, fontweight='bold')\n",
        "fig.set_figheight(6)\n",
        "fig.set_figwidth(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_UijTuZJhp_y"
      },
      "cell_type": "code",
      "source": [
        "import math, time\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# make predictions\n",
        "y_test_pred = model(x_test_tensor)\n",
        "lstm = []\n",
        "# invert predictions\n",
        "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
        "y_train = scaler.inverse_transform(y_train_lstm.detach().numpy())\n",
        "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
        "y_test = scaler.inverse_transform(y_test_lstm_tensor.detach().numpy())\n",
        "\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "lstm.append(trainScore)\n",
        "lstm.append(testScore)\n",
        "lstm.append(training_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ePRLskNmhp_y"
      },
      "cell_type": "code",
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(price)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[lookback:len(y_train_pred)+lookback, :] = y_train_pred\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(price)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(y_train_pred)+lookback-1:len(price)-1, :] = y_test_pred\n",
        "\n",
        "original = scaler.inverse_transform(price['Close'].values.reshape(-1,1))\n",
        "\n",
        "predictions = np.append(trainPredictPlot, testPredictPlot, axis=1)\n",
        "predictions = np.append(predictions, original, axis=1)\n",
        "result = pd.DataFrame(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-tH05FABhp_z"
      },
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[0],\n",
        "                    mode='lines',\n",
        "                    name='Train prediction')))\n",
        "fig.add_trace(go.Scatter(x=result.index, y=result[1],\n",
        "                    mode='lines',\n",
        "                    name='Test prediction'))\n",
        "fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[2],\n",
        "                    mode='lines',\n",
        "                    name='Actual Value')))\n",
        "fig.update_layout(\n",
        "    xaxis=dict(\n",
        "        showline=True,\n",
        "        showgrid=True,\n",
        "        showticklabels=False,\n",
        "        linecolor='white',\n",
        "        linewidth=2\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title_text='Close (USD)',\n",
        "        titlefont=dict(\n",
        "            family='Rockwell',\n",
        "            size=12,\n",
        "            color='white',\n",
        "        ),\n",
        "        showline=True,\n",
        "        showgrid=True,\n",
        "        showticklabels=True,\n",
        "        linecolor='white',\n",
        "        linewidth=2,\n",
        "        ticks='outside',\n",
        "        tickfont=dict(\n",
        "            family='Rockwell',\n",
        "            size=12,\n",
        "            color='white',\n",
        "        ),\n",
        "    ),\n",
        "    showlegend=True,\n",
        "    template = 'plotly_dark'\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "annotations = []\n",
        "annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n",
        "                              xanchor='left', yanchor='bottom',\n",
        "                              text='Results (LSTM)',\n",
        "                              font=dict(family='Rockwell',\n",
        "                                        size=26,\n",
        "                                        color='white'),\n",
        "                              showarrow=False))\n",
        "fig.update_layout(annotations=annotations)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "Ibf2gv4Qhp_z"
      },
      "cell_type": "code",
      "source": [
        "!pip install chart-studio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LXr3BZs6hp_z"
      },
      "cell_type": "code",
      "source": [
        "# import chart_studio.plotly as py\n",
        "# import chart_studio\n",
        "\n",
        "# chart_studio.tools.set_credentials_file(username='rodolfo_saldanha', api_key='zWJIVWJs23wfiAp516Mh')\n",
        "# py.iplot(fig, filename='stock_prediction_lstm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rjpe8i-Php_z"
      },
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(GRU, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "        out, (hn) = self.gru(x, (h0.detach()))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nfWFqY2nhp_0"
      },
      "cell_type": "code",
      "source": [
        "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AhuqmiqMhp_0"
      },
      "cell_type": "code",
      "source": [
        "hist = np.zeros(num_epochs)\n",
        "start_time = time.time()\n",
        "gru = []\n",
        "\n",
        "for t in range(num_epochs):\n",
        "    y_train_pred = model(x_train)\n",
        "\n",
        "    loss = criterion(y_train_pred, y_train_gru)\n",
        "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
        "    hist[t] = loss.item()\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "training_time = time.time()-start_time\n",
        "print(\"Training time: {}\".format(training_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QeuZe2BRhp_0"
      },
      "cell_type": "code",
      "source": [
        "predict = pd.DataFrame(scaler.inverse_transform(y_train_pred.detach().numpy()))\n",
        "original = pd.DataFrame(scaler.inverse_transform(y_train_gru.detach().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lf5fFYRWhp_0"
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "ax = sns.lineplot(x = original.index, y = original[0], label=\"Data\", color='royalblue')\n",
        "ax = sns.lineplot(x = predict.index, y = predict[0], label=\"Training Prediction (GRU)\", color='tomato')\n",
        "ax.set_title('Stock price', size = 14, fontweight='bold')\n",
        "ax.set_xlabel(\"Days\", size = 14)\n",
        "ax.set_ylabel(\"Cost (USD)\", size = 14)\n",
        "ax.set_xticklabels('', size=10)\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "ax = sns.lineplot(data=hist, color='royalblue')\n",
        "ax.set_xlabel(\"Epoch\", size = 14)\n",
        "ax.set_ylabel(\"Loss\", size = 14)\n",
        "ax.set_title(\"Training Loss\", size = 14, fontweight='bold')\n",
        "fig.set_figheight(6)\n",
        "fig.set_figwidth(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CVjVWgzThp_1"
      },
      "cell_type": "code",
      "source": [
        "import math, time\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# make predictions\n",
        "y_test_pred = model(x_test)\n",
        "\n",
        "# invert predictions\n",
        "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
        "y_train = scaler.inverse_transform(y_train_gru.detach().numpy())\n",
        "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
        "y_test = scaler.inverse_transform(y_test_gru.detach().numpy())\n",
        "\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "gru.append(trainScore)\n",
        "gru.append(testScore)\n",
        "gru.append(training_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "T0SJoPGthp_1"
      },
      "cell_type": "code",
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(price)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[lookback:len(y_train_pred)+lookback, :] = y_train_pred\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(price)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(y_train_pred)+lookback-1:len(price)-1, :] = y_test_pred\n",
        "\n",
        "original = scaler.inverse_transform(price['Close'].values.reshape(-1,1))\n",
        "\n",
        "predictions = np.append(trainPredictPlot, testPredictPlot, axis=1)\n",
        "predictions = np.append(predictions, original, axis=1)\n",
        "result = pd.DataFrame(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lHNND6KThp_1"
      },
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[0],\n",
        "                    mode='lines',\n",
        "                    name='Train prediction')))\n",
        "fig.add_trace(go.Scatter(x=result.index, y=result[1],\n",
        "                    mode='lines',\n",
        "                    name='Test prediction'))\n",
        "fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[2],\n",
        "                    mode='lines',\n",
        "                    name='Actual Value')))\n",
        "fig.update_layout(\n",
        "    xaxis=dict(\n",
        "        showline=True,\n",
        "        showgrid=True,\n",
        "        showticklabels=False,\n",
        "        linecolor='white',\n",
        "        linewidth=2\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title_text='Close (USD)',\n",
        "        titlefont=dict(\n",
        "            family='Rockwell',\n",
        "            size=12,\n",
        "            color='white',\n",
        "        ),\n",
        "        showline=True,\n",
        "        showgrid=True,\n",
        "        showticklabels=True,\n",
        "        linecolor='white',\n",
        "        linewidth=2,\n",
        "        ticks='outside',\n",
        "        tickfont=dict(\n",
        "            family='Rockwell',\n",
        "            size=12,\n",
        "            color='white',\n",
        "        ),\n",
        "    ),\n",
        "    showlegend=True,\n",
        "    template = 'plotly_dark'\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "annotations = []\n",
        "annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n",
        "                              xanchor='left', yanchor='bottom',\n",
        "                              text='Results (GRU)',\n",
        "                              font=dict(family='Rockwell',\n",
        "                                        size=26,\n",
        "                                        color='white'),\n",
        "                              showarrow=False))\n",
        "fig.update_layout(annotations=annotations)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lrpcQQ68hp_1"
      },
      "cell_type": "code",
      "source": [
        "lstm = pd.DataFrame(lstm, columns=['LSTM'])\n",
        "gru = pd.DataFrame(gru, columns=['GRU'])\n",
        "result = pd.concat([lstm, gru], axis=1, join='inner')\n",
        "result.index = ['Train RMSE', 'Test RMSE', 'Train Time']\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5k92uuQ4hp_2"
      },
      "cell_type": "code",
      "source": [
        "py.iplot(fig, filename='stock_prediction_gru')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}