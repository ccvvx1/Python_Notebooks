{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVDV5YJ9Ngdw"
   },
   "source": [
    "# Example usage of [stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion)\n",
    "Pure-pytorch version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od2eF2ZwH_6W"
   },
   "source": [
    "### Check the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfirUQVeMvm8"
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVJBUstIgMI3"
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HG8OCXSIGLQ"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-LhllLN-5ph"
   },
   "outputs": [],
   "source": [
    "#@title install dependencies\n",
    "#! git clone https://github.com/ashawkey/stable-dreamfusion.git\n",
    "\n",
    "%cd stable-dreamfusion\n",
    "\n",
    "# install requirements\n",
    "! pip install -r requirements.txt\n",
    "! pip install git+https://github.com/NVlabs/nvdiffrast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5hYlE0mjbbr",
    "outputId": "f2b68b66-08db-407b-a7c3-0e9d578051ae"
   },
   "outputs": [],
   "source": [
    "%cd stable-dreamfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGzIiGiUd-xQ",
    "outputId": "75de614d-e0b8-44c4-d043-0fd17926e6b9"
   },
   "outputs": [],
   "source": [
    "%cd stable-dreamfusion/pretrained/zero123\n",
    "!wget https://zero123.cs.columbia.edu/assets/zero123-xl.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INnaCmsAd-xR"
   },
   "outputs": [],
   "source": [
    "%cd ../../../stable-dreamfusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VklXFNisIrDo"
   },
   "source": [
    "### Training & Testing\n",
    "* It takes about 0.7s per training step, so the default 5000 training steps take around 1 hour to finish. A larger `Training_iters` usually leads to better results.\n",
    "* If CUDA OOM, try to decrease `Num_steps`, `Upsample_steps`, and `Training_nerf_resolution`.\n",
    "* If the NeRF fails to learn anything (empty scene, only background), try to decrease `Lambda_entropy` which regularizes the learned opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4WGvOBBI1ae"
   },
   "outputs": [],
   "source": [
    "#@markdown ####**Training Settings:**\n",
    "Prompt_text = \"an apple\" #@param {type: 'string'}\n",
    "Training_iters = 3000 #@param {type: 'integer'}\n",
    "Learning_rate = 1e-3 #@param {type: 'number'}\n",
    "Training_nerf_resolution = 64  #@param {type: 'integer'}\n",
    "# CUDA_ray = True #@param {type: 'boolean'}\n",
    "# View_dependent_prompt = True #@param {type: 'boolean'}\n",
    "# FP16 = True #@param {type: 'boolean'}\n",
    "Seed = 0 #@param {type: 'integer'}\n",
    "Lambda_entropy = 1e-4 #@param {type: 'number'}\n",
    "Num_steps = 64 #@param {type: 'number'}\n",
    "Upsample_steps = 32 #@param {type: 'number'}\n",
    "albedo_iter_ratio = 1e-3 #@param {type: 'number'}\n",
    "Checkpoint = 'latest' #@param {type: 'string'}\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**Output Settings:**\n",
    "Workspace = \"trial\" #@param{type: 'string'}\n",
    "# Save_mesh = True #@param {type: 'boolean'}\n",
    "\n",
    "# processings\n",
    "Prompt_text = \"'\" + Prompt_text + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZicV2eshd-xS"
   },
   "outputs": [],
   "source": [
    "%cd stable-dreamfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHHjlAkwJDa5"
   },
   "outputs": [],
   "source": [
    "#@title start training\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "%run main.py -O2 --albedo_iter_ratio 1e-3  --albedo --text {Prompt_text} --workspace {Workspace} --iters {Training_iters} --lr {Learning_rate} --w {Training_nerf_resolution} --h {Training_nerf_resolution} --seed {Seed} --lambda_entropy {Lambda_entropy} --ckpt {Checkpoint} --save_mesh --num_steps {Num_steps} --upsample_steps {Upsample_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg1mExGud-xT"
   },
   "outputs": [],
   "source": [
    "!python guidance/zero123_utils.py  data/anya_front.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9ze7qsQd-xT"
   },
   "outputs": [],
   "source": [
    "!mkdir pretrained/omnidata\n",
    "%cd pretrained/omnidata\n",
    "# assume gdown is installed\n",
    "!gdown '1Jrh-bRnJEjyMCS7f-WsaFlccfPjJPPHI&confirm=t' # omnidata_dpt_depth_v2.ckpt\n",
    "!gdown '1wNxVO4vVbDEMEpnAi_jwQObf2MFodcBR&confirm=t' # omnidata_dpt_normal_v2.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h84fdV1pd-xT"
   },
   "outputs": [],
   "source": [
    "!python preprocess_image.py data/anya_front.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7II55pod-xT"
   },
   "outputs": [],
   "source": [
    "!python main.py -O --image data/anya_front_rgba.png --workspace trial_image --iters 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BJ6-1tkaRTpy"
   },
   "outputs": [],
   "source": [
    "#@markdown ####**Testing Settings:**\n",
    "\n",
    "Workspace_test = \"trial\" #@param{type: 'string'}\n",
    "# Save_mesh = True #@param {type: 'boolean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6liVfcPZRGWD"
   },
   "outputs": [],
   "source": [
    "#@title testing\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "%run main.py -O2 --test --workspace {Workspace_test} --save_mesh --max_ray_batch 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxzEhYT5PQIV"
   },
   "source": [
    "### Display results\n",
    "* RGB and Depth video are located at `{Workspace}/results/*.mp4`\n",
    "* Mesh is under `{Workspace}/mesh/`, you could see three files named `mesh.obj`, `mesh.mtl`, and `albedo.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmmiVeUDOXI6"
   },
   "outputs": [],
   "source": [
    "#@title display RGB video\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def get_latest_file(path):\n",
    "  dir_list = glob.glob(path)\n",
    "  dir_list.sort(key=lambda x: os.path.getmtime(x))\n",
    "  return dir_list[-1]\n",
    "\n",
    "def show_video(video_path, video_width = 600):\n",
    "\n",
    "  video_file = open(video_path, \"r+b\").read()\n",
    "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "\n",
    "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
    "rgb_video = get_latest_file(os.path.join(Workspace, 'results', '*_rgb.mp4'))\n",
    "show_video(rgb_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAUwd_aMd-xV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
